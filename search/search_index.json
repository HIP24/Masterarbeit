{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#thema-masterarbeit","title":"Thema Masterarbeit","text":"<p>Virtualisierung eines Echtzeit-Betriebssystems zur Steuerung eines Roboters mit Schwerpunkt auf die  Einhaltung der Echtzeit </p>"},{"location":"#kurze-umschreibung","title":"Kurze Umschreibung","text":"<p>Erstellung einer Echtzeit-Robotersteuerungsplattform unter Verwendung von Salamander OS, Xenomai, QEMU  und PCV-521 in der Yocto-Umgebung. Die Plattform basiert auf Salamander OS und nutzt Xenomai f\u00fcr Echtzeit- Funktionen. Dazu muss im ersten Schritt die Virtualisierungsplattform evaluiert werden. (QEMU, Hyper-V, Virtual  Box, etc.) Als weiterer Schritt folgt die Anbindung eines Roboters \u00fcber eine VARAN-Bus Schnittstelle. Das  gesamte System wird in der Yocto-Umgebung erstellt und konfiguriert.  Das Hauptziel der Arbeit ist es, herauszufinden, wie die Integration von Echtzeit-Funktionen und effizienten  Kommunikationssystemen in eine Robotersteuerungsplattform die Reaktionszeit und Zuverl\u00e4ssigkeit von  Roboteranwendungen verbessern kann. </p>"},{"location":"#masterarbeit","title":"Masterarbeit","text":"<p>Hier ist die Masterarbeit.</p> <p>Info</p> <p>Diese Masterarbeit wird t\u00e4glich aktualisiert. Zu einem sp\u00e4teren Zeitpunkt kann mehr Inhalt vorhanden sein.</p> Fortschritt  der Masterarbeit:"},{"location":"general/checklist/","title":"Checklist","text":""},{"location":"general/checklist/#done","title":"Done","text":"<ul> <li> Install Ubuntu 22.04.3 LTS</li> <li> Local Yocto Build: Salamander4 </li> <li> Linux Kernel Configuration with Xenomai</li> <li> Boot Salamander4 in QEMU under native Ubuntu </li> <li> Configured bridge for QEMU</li> <li> Connected LasalClass2 with [Salamander 4]</li> <li> Enabled access to the vsocket for guest</li> <li> trace-cmd and kernelshark with Salamander4 as guest </li> <li> Used the Xenomai test suite: latency -T 60` </li> <li> Isolated host CPU for guest</li> <li> Latency got better after isolation</li> <li> Analyze Host and Guest Processes</li> <li> Latency got much better after rt-patch</li> <li> Latency got even better after Intels RT_Performance_Tuning_Best_Practice_KVM_VM.pdf: xenomai_compare.md</li> </ul>"},{"location":"general/checklist/#missing","title":"Missing","text":"<ul> <li> Inspect kvm_exit reasons</li> <li> Adapt QEMU script to work with chrt</li> <li> </li> <li> </li> <li> </li> </ul>"},{"location":"general/checklist/#appendix-hardware-and-os-configuration-checklist","title":"Appendix: Hardware and OS configuration checklist","text":"<p>Real-time programming with Linux This serves as a non-exhaustive starting point on the things to check for the hardware and OS. The list is constructed based on my survey of the literature (mostly conference talks, with some internet articles). Remember to always validate the final scheduling latency with something like cyclictest!</p> <ul> <li> Disable SMT</li> <li> Disable dynamic frequency scaling</li> <li> Check for the presence of system management interrupts; if possible, consult with the hardware vendor (remember to always verify their claims)</li> <li> Understand the NUMA of the computer and minimize cross-node memory access within the RT process</li> <li> Disable RT throttling</li> <li> Disable any unneeded RT services/daemons already running on the OS</li> <li> Possibly setup isolcpu (or use cgroups to accomplish the same thing)</li> <li>[] Look into kernel configurations that may affect RT performance such as CONFIG_LOCKUP_DETECTOR, CONFIG_DETECT_HUNG_TASK, CONFIG_NO_HZ, CONFIG_HZ_*, CONFIG_NO_HZ_FULL, and possibly more.</li> <li>[] Configure the memory lock and rtprio permissions in /etc/security/limits.d.</li> <li> Do the latency_reduction_steps.md</li> <li>[]</li> </ul>"},{"location":"general/components/","title":"Components","text":""},{"location":"general/components/#angabe","title":"Angabe","text":"<p>Virtualisierung eines Echtzeit-Betriebssystems zur Steuerung eines Roboters mit Schwerpunkt auf die Einhaltung der Echtzeit</p>"},{"location":"general/components/#yocto-umgebung","title":"Yocto-Umgebung","text":"<p>Build with Yocto</p>"},{"location":"general/components/#salamander-os","title":"Salamander OS","text":"<p>Build LRT</p>"},{"location":"general/components/#xenomai","title":"Xenomai","text":"<p>Preempt_rt.png Xenomai.png</p>"},{"location":"general/components/#lasal-class","title":"Lasal CLass","text":"<p>Lasal Class 2 english Lasal Class 2 deutsch</p>"},{"location":"general/components/#qemu","title":"QEMU","text":"<p>QEMU documentation</p>"},{"location":"general/components/#pcv-521","title":"PCV-521","text":"<p>PCI-Einsteckmodul, das als Schnittstelle zwischen einem PC und dem VARAN-Bus dient PCV 522.pdf </p>"},{"location":"general/documentations_and_links/","title":"Documentations","text":"<ul> <li>Yocto Project</li> <li>QEMU</li> <li>Paravirtualized KVM features</li> <li>QEMU options</li> <li>Kernel Parameters</li> <li>Xenomai</li> <li>Trace-cmd</li> <li>KernelShark</li> <li>Kernelconfig</li> <li>Sigmatek <ul> <li>Build with Yocto</li> <li>Build LRT</li> </ul> </li> </ul>"},{"location":"general/documentations_and_links/#links","title":"Links","text":""},{"location":"general/documentations_and_links/#ftrace","title":"ftrace","text":"<p>Analyze the Linux kernel with ftrace ftrace - Function Tracer ftrace: trace your kernel functions! </p>"},{"location":"general/documentations_and_links/#trace-cmd","title":"trace-cmd","text":"<p>Youtube: Tracing VMs Seeing How Host and Guest Interact - Steven Rostedt, Google trace-cmd Tutorial trace-cmd Presentation trace-cmd Documentation trace-cmd: A front-end for Ftrace Kernel tracing with trace-cmd Git repo trace-cmd </p>"},{"location":"general/documentations_and_links/#sigmatek","title":"Sigmatek","text":"<p>Sigmatek Git Branches</p>"},{"location":"general/documentations_and_links/#ai","title":"AI","text":"<p>ChatGPT prompt splitter</p>"},{"location":"general/draft/","title":"Draft","text":""},{"location":"general/draft/#from-paper-virt-mixed","title":"from Paper Virt. mixed...","text":"<p>Instead, the PREEMPT RT patch provides several mechanisms like high-resolution timers, threaded interrupt handlers, priority inheritance implementation, Preemptible Read-Copy-Update (RCU), real-time schedulers, and a memory allocator.</p>"},{"location":"general/draft/#numa","title":"NUMA","text":"<pre><code>sigma_ibo@sigma-ibo:~$ numactl --hardware\navailable: 1 nodes (0)\nnode 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13\nnode 0 size: 31772 MB\nnode 0 free: 10107 MB\nnode distances:\nnode   0 \n  0:  10\n</code></pre> <p>The output of the numactl --hardware command shows the Non-Uniform Memory Access (NUMA) configuration of your system.</p> <p>Here\u2019s what each line means:</p> <p>available: 1 nodes (0): This means that your system has 1 NUMA node available, and it is identified as node 0. node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13: This line lists the CPUs that are part of node 0. In this case, CPUs 0 through 13 are part of this node. node 0 size: 31772 MB: This indicates that node 0 has a total of 31772 MB of memory. node 0 free: 10107 MB: This shows that out of the total memory, 10107 MB is currently free and available for use. node distances:: This section provides the relative distances between different NUMA nodes. Since you only have one node, there is only one entry here. 0: 10: This indicates that the distance from node 0 to itself is 10. The distance is a relative measure of the latency of memory access between nodes. A lower number means lower latency. Since your system has only one NUMA node, all memory access is local, and you don\u2019t need to worry about cross-node memory access. However, if you add more nodes in the future, you\u2019ll need to consider the placement of processes and memory to minimize cross-node memory access. This can be done by setting CPU and memory affinity for your processes or threads, partitioning data across the NUMA nodes, and using NUMA-aware allocators. Always remember to measure and profile the NUMA characteristics of your application to identify areas where cross-node access is high. If you\u2019re not comfortable making these changes yourself, it might be a good idea to seek help from someone who is.</p> <p>The \u201cdistance\u201d in NUMA architecture doesn\u2019t refer to a physical distance, but rather to a measure of memory access latency. In this context, the distance from a node to itself is the baseline latency for accessing its own local memory.</p> <p>The value \u201c10\u201d is a relative measure. It doesn\u2019t represent an absolute time or delay, but serves as a reference point for comparing memory access latencies within the system. When comparing this to the latency of accessing memory on other nodes (in a multi-node system), a lower value would indicate lower latency.</p> <p>So, when it says the distance from node 0 to itself is 10, it means that the latency for accessing local memory is set as the baseline reference value of 10. If there were other nodes, their distances would be compared to this baseline to determine whether accessing memory on those nodes would be faster or slower.</p> <p>In a single-node system like yours, this value doesn\u2019t have much practical impact since all memory access is local. But in a multi-node system, understanding these distances can be crucial for optimizing performance and minimizing latency.</p>"},{"location":"general/protocol/","title":"Protocol","text":""},{"location":"general/protocol/#dual-boot","title":"Dual Boot","text":"<p>1) Flash SSD by installing etcher 2) Ubuntu and Windows on same machine</p>"},{"location":"general/protocol/#install-salamander4-os","title":"Install Salamander4 OS","text":"<p>1) Install Ubuntu 22.04.3 LTS 2) Do everything in build_with_yocto.md</p>"},{"location":"general/protocol/#ssh-to-device","title":"SSH to device","text":"<p>Connect to device with <code>ssh -oHostKeyAlgorithms=+ssh-rsa root@10.10.1.229</code> or <code>ssh -p 22 root@192.168.1.x</code> (changes often)</p>"},{"location":"general/protocol/#lasalclass2-to-device","title":"LasalClass2 to device","text":"<p>Connect LasalClass2 with Salamander 4, IP of Salamander4 device</p>"},{"location":"general/protocol/#configure-bridge-for-qemu","title":"Configure bridge for QEMU","text":"<p>This setup allows the virtual machines to communicate with the outside network through the Ethernet connection provided by either the laptop or the docking station.</p> name device enp0s31f6 Laptop's Ethernet port enx4cd717733f80 Docking station's Ethernet port <ul> <li>Disable ipv4 and ipv6</li> <li>Enter nmtui</li> <li>Edit Connection and \\&lt;Add&gt;. Select Bridge.</li> <li>Edit and \\&lt;Add&gt; Ethernet.</li> <li>Copy name enx4cd717733f80 (4C:D7:17:73:3F:80) of Wired connection 2</li> <li>Edit Connection of Ethernet connection 1 so that it automatically connects.</li> <li>Activate Connection.</li> <li>Result should look like this and this.</li> <li>More info in nmbridge.md. </li> </ul>"},{"location":"general/protocol/#reduce-latency","title":"Reduce latency","text":"<p>We test the system using the Xenomai test suite - <code>latency</code> - <code>clocktest</code> </p>"},{"location":"general/protocol/#max-latency-default","title":"Max Latency default","text":"<p>Default latency  <pre><code>sigma_ibo@pamhal:$ ps -eo pid,psr,comm | grep qemu\n   7295  10 start_qemu.sh\n   7298  17 qemu-system-x86\n</code></pre></p> <p>latency -h -s -T 600 -g max_latency_default_10min.txt</p> <p>lat worst is 4070.018</p>"},{"location":"general/protocol/#max-latency-with-taskset","title":"Max Latency with taskset","text":"<p>To isolate CPUs on your host system (Ubuntu), you can add the <code>isolcpus</code> option to the kernel boot configuration. Here are the steps you can follow:</p> <ol> <li>Open the GRUB configuration file with a text editor. You can use the <code>nano</code> editor for this. Execute the following command in your terminal:     <pre><code>sudo nano /etc/default/grub\n</code></pre></li> <li>Search for the entry <code>GRUB_CMDLINE_LINUX</code> and add <code>isolcpus=0,1,2,3,4</code> (or the corresponding CPU numbers you want to isolate). It should then look like this:     <pre><code>GRUB_CMDLINE_LINUX=\"isolcpus=0,1,2,3,4\"\n</code></pre></li> <li> <p>Save the changes and close the editor. If you are using <code>nano</code>, you can do this by pressing <code>Ctrl+X</code>, then typing <code>Y</code> to save the changes, and finally pressing <code>Enter</code> to close the editor.</p> </li> <li> <p>Update GRUB with the following command:     <pre><code>sudo update-grub\n</code></pre></p> </li> <li>Reboot your system for the changes to take effect.</li> </ol> <p>Check with: <code>cat /sys/devices/system/cpu/isolated</code></p> <pre><code>sigma_ibo@pamhal:~$ cat /sys/devices/system/cpu/online \n0-19\nsigma_ibo@pamhal:~$ cat /sys/devices/system/cpu/isolated\n0-4\n</code></pre> <p>After taskset on CPU4 with <code>qemu_def_2taskset_vsock_nmbridge.sh</code> <pre><code>sigma_ibo@pamhal:$ ps -eo pid,psr,comm | grep qemu\n   8752   0 start_qemu.sh\n   8755   4 qemu-system-x86\n</code></pre> latency -h -s -T 600 -g max_latency_with_taskset_10min.txt</p> <p>lat worst reduced from 4070.018 to 457.545 with stats</p>"},{"location":"general/protocol/#max-latency-with-rt","title":"Max Latency with rt","text":"<p>Technical details of the real-time preemption RT-Tests HOWTO: Build an RT-application Tuning a real-time kernel Paravirtualized KVM features </p>"},{"location":"general/protocol/#enable-preempt_rt-kernel","title":"Enable Preempt_RT Kernel","text":"<p>Either do everything in kernel-patch.md to patch the kernel and enable Fully Preemptible Kernel (RT), or simply enable Ubuntu Pro's real-time kernel, here.</p> <p>Info</p> <p>Before the isolation of CPU x, both kernel threads and user processes were running on this CPU. The user processes included various applications such as msedge, code, bash and qemu-system-x86.</p> <p>After isolating CPU x, only kernel threads and the qemu-system-x86 process appear to be running on this CPU. There do not appear to be any other user processes running on this CPU.</p> <p>The isolcpus option prevents the kernel from scheduling normal (non-real-time) processes on the isolated CPUs. However, there are some exceptions:</p> <ul> <li>If a process is explicitly set to run on an isolated CPU (for example with taskset), it will run on that CPU even if it is isolated.</li> <li>Some kernel threads can run on isolated CPUs because they are not controlled by the normal scheduler. These include the threads you see in your output, such as kthreadd, migration/4, ksoftirqd/4, kworker/4:0-events and others.</li> <li>Interrupts can be handled on isolated CPUs unless they are explicitly redirected with the irqaffinity option.</li> </ul> <p>latency -T 600</p> <p>lat worst reduced from 457.545 to 32.216 with stats</p>"},{"location":"general/protocol/#realtime-priority","title":"Realtime priority","text":"<p>Danger</p> <p>Setting a real-time priority of 99 for a process means that this process has the highest priority in the system and is executed before all other processes. This can result in other processes, including important system processes, not receiving the CPU time they need to function properly. This can lead to system instability and, in the worst case, to the system becoming unresponsive or \"crashing\".</p> <p>It is important to be careful when using real-time priorities and ensure that other important processes still get the CPU time they need. It might be helpful to gradually increase the real-time priority and observe the effects on the system instead of jumping straight to the highest priority.</p> <p>To see the real-time priorities of all running processes, have a look at thread priorities.</p>"},{"location":"general/protocol/#configuring-the-system-for-real-time","title":"Configuring the system for real-time","text":"<p>For now, PREEMPT_RT is a set of patches that is supposed to be applied on top of mainline Linux. Most Linux distributions do not build it by default, and you will most likely have to do it yourself [3]. How this can be done falls outside the scope of this post, but there are plenty of guides out there. Hopefully in the near future, all of PREEMPT_RT's functionality will be merged in to mainline, and Linux distributions will provide RT-enabled kernels out-of-the-box.</p> <p>Once you successfully compiled the RT kernel, the default hardware and OS configurations are usually not tuned correctly for RT. The following hardware and OS configurations should likely always be checked and tuned: latency_reduction_steps.md</p>"},{"location":"general/protocol/#third-process-is-for-latency-minimization","title":"Third process is for latency minimization","text":"<pre><code>13    2972    2972 qemu-system-x86_64 -M pc,ac FF    -     98\n13    2972    2976 qemu-system-x86_64 -M pc,ac FF    -     98\n13    2972    3292 qemu-system-x86_64 -M pc,ac FF    -     90\n13    2972    8699 qemu-system-x86_64 -M pc,ac FF    -     95\n</code></pre> <p>Salamander 4 latency comparison </p>"},{"location":"general/timeline/","title":"Timeline","text":"Date Log Thursday, 08.02.2024 Dual boot Windows and Ubuntu Friday, 09.02.2024 Booted Salamander 4 on Ubuntu Monday, 12.02.2024 Connected Salamander 4 with SSH Tuesday, 13.02.2024 Connected Salamander 4 with Lasal Class 2 (Christian) after configuring bridge Wednesday, 14.02.2024 Installed Windows VM on Ubuntu, installed Lasal Class 2 on Windows VM, connected with Salamander 4 Thursday, 15.02.2024 Run pumpcontrol example successfully Friday, 16.02.2024 Increased virtual CPU in Windows Monday, 19.02.2024 Xenomai-system-tools Tuesday, 20.02.2024 KernelShark Wednesday, 21.02.2024 Local Yocto Build finally done Thursday, 22.02.2024 trace-cmd agent on guest communicates with host Friday, 23.02.2024 Teammeeting and Germany Monday, 26.02.2024 after_bitbake, kernelshark, paths Tuesday, 27.02.2024 Isolate CPUs on host system and let guest run on it Wednesday, 28.02.2024 Host-Guest timestamp sync works with VM, can view KVM Combo plots, does still not work with Salamander4 Thursday, 29.02.2024 useful_links and search_for_x.py Friday, 01.03.2024 checklist.md, nmbridge.md, understand nmbridge Monday, 04.03.2024 Finally: Negotiated kvm time sync protocol with guest Salamander4 Tuesday, 05.03.2024 lat worst reduced from 374.075 to 87.379 Wednesday, 06.03.2024 Add documentation local server Thursday, 07.03.2024 Start Salamander4 CPU with icecc Friday, 08.03.2024 Merge master and readme Monday, 11.03.2024 Kernel patch, richard meeting and settings.json Tuesday, 12.03.2024 real time priorities with chrt -f 50, no success Wednesday, 13.03.2024 Preventing kernel tasks from being scheduled on CPU4 Thursday, 14.03.2024 irq.md Friday, 15.03.2024 Timer 1000Hz Monday, 18.03.2024 kernel_processes.md, kernelshark, start thesis Tuesday, 19.03.2024 Added Zotero, Ubuntu Pro and Ubuntu PREEMPT_RT Wednesday, 20.03.2024 kvm_exit reasons plot Thursday, 21.03.2024 gitlfs and settings.json, plot with and without taskset, write more thesis Friday, 22.03.2024 Literature paper search Monday, 25.03.2024 Start masterthesis Tuesday, 26.03.2024 Write masterthesis Wednesday, 27.03.2024 Write masterthesis Thursday, 28.03.2024 Write masterthesis Friday, 29.03.2024 Write masterthesis Monday, 01.04.2024 Ostern Tuesday, 02.04.2024 bcc tool Wednesday, 03.04.2024 Write masterthesis APIC_WRITE Thursday, 04.04.2024 defconfig, vapic Friday, 05.04.2024 check_smp_affinity and check_CPU_IRQ_usage Monday, 08.04.2024 kvm_exit_vapic_results Tuesday, 09.04.2024 trace-cmd report analysis Wednesday, 10.04.2024 getconf _NPROCESSORS_CONF Thursday, 11.04.2024 Richard Meeting Friday, 12.04.2024 Spec Monday, 15.04.2024 report.sh Tuesday, 16.04.2024 Updated analyze_trace.py, include in thesis Wednesday, 17.04.2024 Describe host and guest tasks Thursday, 18.04.2024 Read 4 papers Friday, 19.04.2024 Read 5 papers Monday, 22.04.2024 Boot ubuntu anew Tuesday, 23.04.2024 Rebuild workspace Wednesday, 24.04.2024 Rebuild workspace, problem_solution Thursday, 25.04.2024 Rebuild workspace, table IRQ CPU Friday, 26.04.2024 compare.md, ps.sh Monday, 29.04.2024 powersave, balanced, performance Tuesday, 30.04.2024 merge and failed_reason Wednesday, 01.05.2024 Feiertag Thursday, 02.05.2024 Ubuntu real-time kernel Friday, 03.05.2024 Steven yt, analyze_events and analyze_tasks Monday, 06.05.2024 report_hardware Tuesday, 07.05.2024 Richard prios, show_all_threads.py Wednesday, 08.05.2024 failed_reason include CPU, reorganize Thursday, 09.05.2024 Feiertag Friday, 10.05.2024 compare kernels Monday, 13.05.2024 compare config, qemu test with 2 cpus Tuesday, 14.05.2024 Hardware and OS configuration checklist Wednesday, 15.05.2024 FINALLY LATENCY REDUCED WITH STATS and PLOT Thursday, 16.05.2024 reorganize, papers and configs Friday, 17.05.2024 real-time-kernel-tuning websites Monday, 20.05.2024 Feiertag Tuesday, 21.05.2024 read 3 papers, compare_2_files.py Wednesday, 22.05.2024 Configure like Intels RT_Performance_Tuning_Best_Practice_KVM_VM.pdf, results in xenomai_compare.md Thursday, 23.05.2024 reorganize, test Salamander 4 Friday, 24.05.2024 QEMU with 2 CPUs Monday, 27.05.2024 Write thesis Tuesday, 28.05.2024 Write thesis Wednesday, 29.05.2024 Write thesis Thursday, 30.05.2024 Feiertag Friday, 31.05.2024"},{"location":"sigmatek/QEMU/nmbridge/","title":"Nmbridge","text":"<ul> <li>Both Laptop and Docking connected</li> <li>Laptop connected, Docking not connected</li> <li>Enable bridge and disable both Laptop and Docking Station</li> <li>Connections</li> <li>Bridge Connections</li> </ul>"},{"location":"sigmatek/salamander4/bash_commands/","title":"Bash commands","text":""},{"location":"sigmatek/salamander4/bash_commands/#essential-packages","title":"Essential packages","text":"<pre><code>sudo apt install gcc g++ libelf-dev libssl-dev make pkg-config gawk wget git diffstat unzip texinfo gcc build-essential chrpath socat cpio python3 python3-pip python3-pexpect xz-utils debianutils iputils-ping python3-git python3-jinja2 libegl1-mesa libsdl1.2-dev python3-subunit mesa-common-dev zstd liblz4-tool file locales libacl1\n</code></pre>"},{"location":"sigmatek/salamander4/bash_commands/#fetch-script-for-yocto","title":"Fetch script for yocto","text":"<p><pre><code>chmod +x fetchsdk.sh  \n./fetchsdk.sh -h  \n./fetchsdk.sh Salamander4_sigmatek-core2  \nchmod +x sigmatek-salamander-glibc-x86_64-salamander-image-core2-64-toolchain-09.07.119_T1701.sh  \n./sigmatek-salamander-glibc-x86_64-salamander-image-core2-64-toolchain-09.07.119_T1701.sh  \n</code></pre> Each time you wish to use the SDK in a new shell session, you need to source the environment setup script e.g. . /opt/salamander/sigmatek-core2/09.07.119_T1701/environment-setup-core2-64-sigmatek-linux . /opt/salamander/sigmatek-core2/09.07.119_T1701/environment-setup-x86-sigmatekmllib32-linux  </p>"},{"location":"sigmatek/salamander4/bash_commands/#mount-storage","title":"Mount storage","text":"<pre><code>sudo blkid  \nsudo nano /etc/fstab  \nsudo mount -a  \nsudo chown -R sigma_ibo /home/sigma_ibo/Develop  \ndf -h ~/Develop  \n</code></pre>"},{"location":"sigmatek/salamander4/bash_commands/#setup","title":"Setup","text":"<pre><code>mkdir ~/Develop  \nmkdir ~/Develop/docker  \nmkdir ~/Develop/jenkins  \nmkdir ~/Develop/jenkins/home  \ncd ~/Develop/jenkins/home  \nssh-keygen -t ed25519 -C \"halil.pamuk@sigmatek.at\"  \ncat ~/.ssh/id_ed25519.pub  \nssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAINJ1I5EULqfk9w3uyyWgkWZmrLur+0v6mOEWk2c6GblE halil.pamuk@sigmatek.at  \ngit clone git@git.sigmatek.at:SIG_SW_BS/salamander/LRT.git  \ngit clone git@git.sigmatek.at:SIG_SW_BS/salamander/SalamanderTools.git  \ngit clone git@git.sigmatek.at:SIG_SW_BS/salamander/u-boot.git  \nmkdir kernel  &amp;&amp; cd kernel\ngit clone git@git.sigmatek.at:SIG_SW_BS/salamander/ipipe.git  \ngit clone git@git.sigmatek.at:SIG_SW_BS/salamander/xenomai  \n</code></pre>"},{"location":"sigmatek/salamander4/bash_commands/#yocto-example","title":"Yocto example","text":"<p>Minimal Yocto Linux image</p>"},{"location":"sigmatek/salamander4/build_LRT/","title":"Build LRT - Salamander 3 Terminal","text":""},{"location":"sigmatek/salamander4/build_LRT/#set-sdk","title":"Set SDK","text":"<pre><code>. /opt/poky/1.6.2/environment-setup-cortexa9-vfp-neon-poky-linux-gnueabi \n</code></pre>"},{"location":"sigmatek/salamander4/build_LRT/#open-2-terminals","title":"Open 2 terminals","text":""},{"location":"sigmatek/salamander4/build_LRT/#terminal-1-ssh-remote-connection","title":"Terminal 1: SSH Remote Connection","text":"<ol> <li>Connect to terminal device with <code>ssh -oHostKeyAlgorithms=+ssh-rsa root@10.10.116.13</code></li> <li>Stop init.d with <code>/etc/init.d/lrt stop</code> or <code>killall -9 LRT*</code></li> <li>Do Terminal 2</li> <li>Start init.d with <code>/etc/init.d/lrt start</code> or <code>./LRTConfig.exe</code></li> </ol>"},{"location":"sigmatek/salamander4/build_LRT/#terminal-2-code-make-and-scp","title":"Terminal 2: Code, make and scp","text":"<ol> <li>Navigate to  <code>~/Develop/jenkins/home/LRT</code>.</li> <li>Open VS Code with  <code>. code</code> and edit LRT</li> <li>Run <code>make</code> when finished</li> <li>Copy contents to terminal device after stopping init.d with <code>scp -oHostKeyAlgorithms=+ssh-rsa build-Linux-arm-S3.meson/*/LRT*.exe root@10.10.116.13:</code></li> </ol>"},{"location":"sigmatek/salamander4/build_LRT/#sigmatek-documentation","title":"Sigmatek Documentation","text":"<p>Build LRT</p>"},{"location":"sigmatek/salamander4/build_with_yocto/","title":"Build with Yocto","text":""},{"location":"sigmatek/salamander4/build_with_yocto/#clone-the-repo","title":"Clone the repo","text":"<p>The first step is to clone the yocto4/salamander git repo: NOTE: In order to clone all dependent repositories, clone the repo with \u2013recurse-submodules. <pre><code>git clone --recurse-submodules git@git.sigmatek.at:SIG_SW_BS/salamander/yocto4/salamander.git\n</code></pre></p>"},{"location":"sigmatek/salamander4/build_with_yocto/#initialize","title":"Initialize","text":"<p>Now you should be left with a subdirectory called salamander.</p> <p>Note: It is a good idea to do the actual build inside a subdirectory named after the specific architecture (e.g. aarch64). This way the directory structure can be used for multible builds without losing track of the overall picture. <pre><code>cd salamander\nmkdir core2 &amp;&amp; cd core2\n</code></pre></p> <p>Next we need to initialize the build environment by calling the init.sh script. Example for Salamander: <pre><code>../init.sh -b build -m sigmatek-core2 -d salamander\n</code></pre> Call the init.sh script without parameters to get a full list of options, like how to build Salamander. You can get a full list of options by calling the script without any parameters. There is also stated what to put after -m option for building an arm version. The -b option defines the build output directory (which will be created by the script if it does not exist).</p>"},{"location":"sigmatek/salamander4/build_with_yocto/#build-image","title":"Build image","text":"<p>Now you can run bitbake for building a gecko-image or salamander-image:</p> <p>To continue the build after an error, start bitbake with -k or \u2013continue. <pre><code>bitbake salamander-image -k\n</code></pre> This process can take up to several hours. So you better are not in a hurry.</p> <p>Afterwards you will find a .lbi-file in the deploy-subdir <code>~/Develop/jenkins/home/buildwithyocto/salamander/core2/build/tmp/deploy/resources/images/sigmatek-core2/</code></p> <p>Hopefully everything goes according to plan. If you encounter a build problem and you punch through it, please write some trouble shooting for this ;-)</p>"},{"location":"sigmatek/salamander4/build_with_yocto/#tipps","title":"Tipps","text":""},{"location":"sigmatek/salamander4/build_with_yocto/#using-less-cores","title":"Using less cores","text":"<p>If you build locally, you may run into the problem that you system is loaded heavily by the yocto build. In fact the load can be so heavy that working with your system on other task can become very slow due to lack of responsiveness.</p> <p>One solution is to tell yocto to use less threads for the build by adding the following line to ~/some/path/build/conf/local.conf</p> <p><pre><code>BB_NUMBER_THREADS = \"${@oe.utils.cpu_count()//2}\"\n</code></pre> In this example we set the number of threads to half the number of cpu cores on the system. In addition one can also set the number of parallel compilations done by make: <pre><code>PARALLEL_MAKE = \"-j${@oe.utils.cpu_count()//2}\"\n</code></pre></p>"},{"location":"sigmatek/salamander4/build_with_yocto/#add-other-computers-to-the-mix","title":"Add other computers to the mix","text":"<p>In <code>buildconfs/default.conf</code> <pre><code>INHERIT += \"icecc\"\nICECC_PARALLEL_MAKE = \"-j 88\"\nICECC_CARET_WORKAROUND = \"1\"\nICECC_DISABLED ??= \"0\"\nICECC_RECIPE_DISABLE = \"\"\n</code></pre> Patch <pre><code>cat &lt;&lt;EOF &gt; meta-virtualization/recipes-core/meta/container-dummy-provides.bb\nDUMMYARCH = \"container-dummy-provides\"\nDUMMYPROVIDES = \"\\\n   /bin/sh \\\n   /usr/bin/env \\\n\"\nLICENSE = \"MIT\"\nEOF\n</code></pre></p>"},{"location":"sigmatek/salamander4/build_with_yocto/#using-jenkins-as-download-mirror","title":"Using jenkins as download mirror","text":"<p>Sometimes it happens that servers that hold repos necessary for builds are down. In this case it is possible to use the jenkins as a download mirror.</p> <p>For this you simply add the following two lines to one of the config files, e.g. site.conf</p> <pre><code>SOURCE_MIRROR_URL ?= \"http://osjenkins.lhau.sigaut.org:8080/userContent/downloads/\"\nINHERIT += \"own-mirrors\"\n</code></pre>"},{"location":"sigmatek/salamander4/build_with_yocto/#sigmatek-documentation","title":"Sigmatek Documentation","text":"<p>Build with Yocto</p>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/","title":"Latency reduction steps","text":""},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#salamander-4-latency-reduction","title":"Salamander 4 latency reduction","text":""},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#bios-configurations","title":"BIOS Configurations","text":"Option Status Hyper Threading disabled Intel SpeedStep\u00ae disabled Intel\u00ae Speed Shift Technology disabled C States disabled VT-d enabled"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#kernel-configurations","title":"Kernel Configurations","text":"<pre><code>GRUB_CMDLINE_LINUX=\"isolcpus=4 rcu_nocbs=4 nohz_full=4 default_hugepagesz=1G hugepagesz=1G hugepages=8 intel_iommu=on rdt=l3cat nmi_watchdog=0 idle=poll clocksource=tsc tsc=reliable noht audit=0 skew_tick=1 intel_pstate=disable intel.max_cstate=0 intel_idle.max_cstate=0 processor.max_cstate=0 processor_idle.max_cstate=0 nosoftlockup nohz=on no_timer_check nospectre_v2 spectre_v2_user=off kvm.kvmclock_periodic_sync=N kvm_intel.ple_gap=0 irqaffinity=0\"\n</code></pre>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#host-configurations","title":"Host Configurations","text":""},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#according-to-real-time-programming-with-linux","title":"According to Real-time programming with Linux","text":""},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#disable-simultaneous-multithreading","title":"Disable simultaneous multithreading","text":"<ul> <li>SMT improves the performance of the CPU but decreases the determinism, thus introducing latency. How this works is outside the scope of this post. As of this writing, it is recommended for SMT to be disabled [4].</li> <li>SMT is usually configured on the BIOS/UEFI level. How this is done varies depending on the system. disable_txt.jpg disable_hyperthreading.jpg</li> </ul>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#disable-dynamic-frequency-scaling","title":"Disable dynamic frequency scaling","text":"<pre><code>-   Modern CPUs ramp down their clock frequencies while idling and ramp up when there is load. This introduces unpredictability as it causes the performance of the CPU to vary with time. Anecdotally, I have noticed an order of magnitude higher worst-case latency when frequency scaling is on compared to when it is off.\n```\nsigma_ibo@sigma-ibo:~/Downloads$ for i in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; do echo \"performance\" | sudo tee $i; done\nperformance\nperformance\nperformance\nperformance\nperformance\nperformance\nperformance\nperformance\nperformance\nperformance\nperformance\nperformance\nperformance\nperformance\n```\nTo automate this process open `crontab -e` and enter\n```\n@reboot for i in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; do echo 'performance' | sudo tee $i; done\n```\n-   How this can be turned off varies per system. Usually this involves configuring both the BIOS/UEFI and Linux (usually by selecting the performance CPU frequency governor).\n</code></pre>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#disable-rt-throttling","title":"Disable RT throttling","text":"<p>Before the widespread availability of multicore systems, if an RT process uses up all of the available CPU time, it can cause the entire system to hang. This is because the Linux scheduler will not run a non-RT process if the RT process continuously hogs the CPU. To avoid this kind of system lockup, especially on desktop-oriented systems where any process can request to be RT, the Linux kernel has a feature to throttle RT processes if it uses 0.95 s out of every 1 s of CPU time. This is done by pausing the process for the last 0.05 s and thus may result in deadline misses during the moments when the process is paused [5]. This can be turned off by writing the value -1 to the file <code>/proc/sys/kernel/sched_rt_runtime_us</code> on every system boot. To permanently disable real-time (RT) throttling, you can add the following line to your <code>/etc/sysctl.conf</code> file:</p> <ol> <li>Open the <code>/etc/sysctl.conf</code> file in a text editor. You might need to use `sudo` to edit this file. <pre><code>sudo nano /etc/sysctl.conf  \n</code></pre></li> <li>Add the following line to the end of the file: <pre><code>kernel.sched_rt_runtime_us = -1  \n</code></pre></li> <li>Save the file and exit the editor.</li> <li>To load the new configuration, run the following command:</li> </ol> <pre><code>sudo sysctl -p  \n</code></pre> <p>This will apply the change immediately and also preserve it across reboots.  </p>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#check-and-make-sure-no-unexpected-rt-processes-are-running-on-your-system","title":"Check and make sure no unexpected RT processes are running on your system","text":"<ul> <li>Sometimes, the base OS can spawn a high-priority RT process on boot as a part of some functionalities it provides. If these functionalities are not needed, it is advisable to disable the offending RT process. Near the end of this post, I will provide an example for this.</li> <li>Sometimes, the kernel can be configured with such a process. See documentation on the kernel build variables CONFIG_LOCKUP_DETECTOR and CONFIG_DETECT_HUNG_TASK.</li> <li>Disabling these processes usually involves consulting with the documentations of your Linux distribution of choice.</li> </ul> <p>There are other configurations that may be relevant depending on your use case, some of which are documented in this talk and this other talk. Additionally, quality-of-life configurations, such the variables in /etc/security/limits.conf, may need to be tuned as well. I encourage the reader to look at pre-made distributions such as the ROS2 real-time Raspberry Pi image (which I incidentally also worked on) for more inspiration. Although providing a complete checklist for system configuration is outside the scope of this post (if it is even possible), I included an non-exhaustive checklist at the bottom of this post as a starting point.</p>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#irq-affinity","title":"IRQ affinity","text":"<p>Remove all possible IRQs from isolated CPU with remove_irqs_from_CPU.sh. Check with table_CPU_IRQ.md and cat <code>/proc/interrupts</code>.</p>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#rcu-cpu-offloading","title":"RCU CPU offloading","text":"<p>Add <code>rcu_nocbs=13</code> as boot parameter for CPU offloading in <code>sudo nano /etc/default/grub</code> <pre><code>GRUB_CMDLINE_LINUX=\"isolcpus=13 rcu_nocbs=13\"\n</code></pre></p>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#suppress-rcu-cpu-stall","title":"Suppress rcu cpu stall","text":"<pre><code>echo 1 | sudo tee /sys/module/rcupdate/parameters/rcu_cpu_stall_suppress\n</code></pre>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#maybe","title":"Maybe?","text":"<pre><code>echo 200 | sudo tee /sys/module/rcupdate/parameters/rcu_cpu_stall_timeout\n</code></pre>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#start-qemu-normally-and-give-all-qemu-threads-rt-priority","title":"Start QEMU normally and give all QEMU threads rt-priority","text":"<p>Start QEMU normally with idle=poll. Give all QEMU threads rt-priority. <pre><code>ps -T -p $(pgrep -f \"qemu-system-x86_64 -M pc,ac\") | awk '{print $2}' | tail -n +2 | xargs -I {} sudo chrt -r -p 99 {}\n</code></pre></p>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#kill-all-running-user-processes","title":"Kill all running user processes","text":"<p>Make sure there is no other running process <pre><code>sudo kill &lt;pid&gt;\n</code></pre></p>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#according-to-intel","title":"According to Intel","text":""},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#set-cpu-affinity-for-systemd-services","title":"Set CPU Affinity for systemd services","text":"<p>Open <code>/etc/systemd/system.conf</code> with a text editor (like nano or vi) with root privileges:    <pre><code>sudo nano /etc/systemd/system.conf\n</code></pre>    Find the line that starts with <code>#CPUAffinity=</code> and change it to <code>CPUAffinity=0 1 2 3 5 6 7 8 9 10 11 12 13</code>. Save and close the file.</p>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#cache-isolation-for-cpu-and-gpu","title":"Cache Isolation for CPU and GPU","text":"<p>To perform cache isolation for CPU and GPU, you can use the Linux <code>resctrl</code> interface. Here are the general steps:</p> <ul> <li> <p>Enable the resctrl filesystem: This is usually done by adding <code>resctrl</code> to your kernel command line. You can do this by editing your bootloader configuration. For GRUB, you would edit <code>/etc/default/grub</code> and add <code>resctrl</code> to the <code>GRUB_CMDLINE_LINUX_DEFAULT</code> line, then update GRUB with <code>sudo update-grub</code> and reboot.</p> </li> <li> <p>Create a resctrl group: Resctrl groups are used to apply different policies to different sets of processes. You can create a new group like this:       <pre><code>sudo mkdir /sys/fs/resctrl/mygroup\n</code></pre>       Replace <code>mygroup</code> with the name you want to use for the group.</p> </li> <li> <p>Assign CPUs to the group: You can assign CPUs to the group by writing to the <code>cpus</code> file in the group's directory. For example, to assign CPUs 0 and 1 to <code>mygroup</code>, you would do:        <pre><code>echo 0-1 | sudo tee /sys/fs/resctrl/mygroup/cpus\n</code></pre></p> </li> <li>Set the cache allocation for the group: You can set the cache allocation by writing to the <code>schemata</code> file in the group's directory. The exact value will depend on your specific needs and system configuration. Here's an example that sets 50% of the L3 cache for code (C) and data (D) on socket 0 to <code>mygroup</code>:        <pre><code>echo \"L3:0=ff00ff;1=ff00ff\" | sudo tee /sys/fs/resctrl/mygroup/schemata\n</code></pre></li> <li>Assign tasks to the group: Finally, you can assign tasks (processes or threads) to the group by writing their PID to the <code>tasks</code> file in the group's directory. For example, to assign a task with PID 12345 to <code>mygroup</code>, you would do:        <pre><code>echo 12345 | sudo tee /sys/fs/resctrl/mygroup/tasks\n</code></pre></li> </ul>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#set-cpu-affinity-of-irq-thread-to-cpu-0","title":"Set CPU Affinity of IRQ thread to CPU 0","text":"<p>First, find the process ID (PID) of the IRQ thread for NVME:    <pre><code>ps -e | grep 'irq/.*nvme'\n</code></pre>    Then, use the <code>taskset</code> command to set the CPU affinity of this thread to CPU 0. Replace <code>&lt;pid&gt;</code> with the PID from the previous command:    <pre><code>sudo taskset -a -p -c 0 &lt;pid&gt;\n</code></pre></p>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#set-device-driver-work-queue-to-cpu-0","title":"Set Device Driver Work Queue to CPU 0","text":"<pre><code>echo 1 | sudo tee /sys/devices/virtual/workqueue/cpumask\necho 1 | sudo tee /sys/bus/workqueue/devices/writeback/cpumask\n</code></pre>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#disable-machine-check","title":"Disable Machine Check","text":"<pre><code>echo 0 | sudo tee /sys/devices/system/machinecheck/machinecheck0/check_interval\n</code></pre>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#stop-certain-services","title":"Stop Certain Services","text":"<pre><code>sudo systemctl stop irqbalance.service\nsudo systemctl stop thermald.service\nsudo systemctl stop wpa_supplicant.service\n</code></pre>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#qemu-configurations","title":"QEMU Configurations","text":""},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#tune-lapic-timer-advance","title":"Tune lapic timer advance","text":"<p>You can set the value of the lapic timer advance to 7500 with this command:    <pre><code>echo 7500 | sudo tee /sys/module/kvm/parameters/lapic_timer_advance_ns\n</code></pre>    This value might be different for different chips.</p>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#set-qemu-options-for-real-time-vm","title":"Set QEMU options for real-time VM","text":"<p>You can set several options when starting your QEMU virtual machine to improve real-time performance. Here are some examples:    - <code>-realtime mlock=on</code>: This option locks the memory of the VM to avoid swapping and lazy allocation.    - <code>-balloon none</code>: This option disables the balloon driver, which can free and return memory to the host OS.    - <code>-mem-prealloc -mem-path /dev/hugepages/</code>: These options enable the use of hugepages, which can reduce TLB misses and improve performance.</p>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#set-cpu-affinity-and-scheduling-policy-of-qemu-cpu-threads","title":"Set CPU affinity and scheduling policy of QEMU CPU threads","text":"<p>You can set the CPU affinity of the QEMU CPU threads to specific CPUs (in this case, CPUs 2 and 3) and set the scheduling policy to FIFO with the highest priority. You'll need to find the PIDs of the QEMU CPU threads first. Once you have the PIDs, you can use the <code>taskset</code> and <code>chrt</code> commands to set the CPU affinity and scheduling policy. Replace <code>&lt;pid&gt;</code> with the PID of the thread:    <pre><code>sudo taskset -a -p -c 2,3 &lt;pid&gt;\nsudo chrt -f -p 99 &lt;pid&gt;\n</code></pre></p>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#passthrough-pci-devices-into-the-vm","title":"Passthrough PCI devices into the VM","text":"<p>If you need to passthrough PCI devices into the VM, you can do so using the <code>-device vfio-pci,host=xx:xx.x</code> option when starting your QEMU virtual machine. Replace <code>xx:xx.x</code> with the PCI address of the device you want to passthrough.</p>"},{"location":"sigmatek/salamander4/latency_reduction/latency_reduction_steps/#trace-latency","title":"Trace latency","text":"<pre><code>latency -h -s -T 600 -g max_latency_rt.txt\n</code></pre>"},{"location":"sigmatek/salamander4/latency_reduction/IRQaffinity/IRQ_affinity/","title":"IRQ affinity","text":""},{"location":"sigmatek/salamander4/latency_reduction/IRQaffinity/IRQ_affinity/#select-best-cpu-for-qemu","title":"Select best CPU for QEMU","text":"<pre><code>sigma_ibo@pamhal:$ cat /sys/devices/system/cpu/cpu*/cpufreq/cpuinfo_max_freq\n5000000\n5000000\n5000000\n4000000\n4000000\n4000000\n4000000\n4000000\n4000000\n4000000\n4000000\n5000000\n5000000\n5000000\n5200000\n5200000\n5200000\n5200000 -&gt; 17\n5000000\n5000000\n</code></pre>"},{"location":"sigmatek/salamander4/latency_reduction/IRQaffinity/IRQ_affinity/#check-which-irqs-use-cpu-x","title":"Check which IRQs use CPU x","text":"<p>check_smp_affinity.sh: <pre><code>./check_smp_affinity.sh 19\nCPU 19 IRQ affinity:\n0\n2\n3\n4\n5\n6\n7\n10\n11\n13\n15\n131\n172\n188\n189\n192\n</code></pre></p>"},{"location":"sigmatek/salamander4/latency_reduction/IRQaffinity/IRQ_affinity/#check-the-mask-of-irq","title":"Check the mask of IRQ","text":"<p>The mask for IRQ0 for example would be:  <pre><code>cat /proc/irq/0/smp_affinity\nfffff\n</code></pre></p>"},{"location":"sigmatek/salamander4/latency_reduction/IRQaffinity/IRQ_affinity/#change-permissions-for-the-irqs","title":"Change permissions for the IRQs","text":"<p>In order to change the mask, first give permissions: <pre><code>sudo chmod 777 /proc/irq/*/smp_affinity\n</code></pre></p>"},{"location":"sigmatek/salamander4/latency_reduction/IRQaffinity/IRQ_affinity/#change-mask-of-irq","title":"Change Mask of IRQ","text":"<p>Then change the mask with  <pre><code>sudo echo 7ffff &gt; /proc/irq/0/smp_affinity\n</code></pre></p>"},{"location":"sigmatek/salamander4/latency_reduction/IRQaffinity/IRQ_affinity/#check-again-the-changed-mask-of-irq","title":"Check again the changed mask of IRQ","text":"<pre><code>cat /proc/irq/0/smp_affinity\ndffff\n</code></pre>"},{"location":"sigmatek/salamander4/latency_reduction/IRQaffinity/IRQ_affinity/#check-again-which-irqs-use-cpu-19","title":"Check again which IRQs use CPU 19","text":"<p>CPU19 is being used by IRQs with check_smp_affinity.sh (IRQ0 is not listed anymore):  <pre><code>0\n2\n3\n4\n5\n6\n7\n10\n11\n12\n13\n15\n133\n172\n173\n189\n191\n</code></pre></p>"},{"location":"sigmatek/salamander4/latency_reduction/IRQaffinity/IRQ_affinity/#batch-change-permissions","title":"Batch change permissions","text":"<pre><code>sudo chmod 777 /proc/irq/0/smp_affinity\nsudo chmod 777 /proc/irq/2/smp_affinity\nsudo chmod 777 /proc/irq/3/smp_affinity\nsudo chmod 777 /proc/irq/4/smp_affinity\nsudo chmod 777 /proc/irq/5/smp_affinity\nsudo chmod 777 /proc/irq/6/smp_affinity\nsudo chmod 777 /proc/irq/7/smp_affinity\nsudo chmod 777 /proc/irq/10/smp_affinity\nsudo chmod 777 /proc/irq/11/smp_affinity\nsudo chmod 777 /proc/irq/12/smp_affinity\nsudo chmod 777 /proc/irq/13/smp_affinity\nsudo chmod 777 /proc/irq/15/smp_affinity\nsudo chmod 777 /proc/irq/133/smp_affinity\nsudo chmod 777 /proc/irq/172/smp_affinity\nsudo chmod 777 /proc/irq/173/smp_affinity\nsudo chmod 777 /proc/irq/189/smp_affinity\nsudo chmod 777 /proc/irq/191/smp_affinity\n</code></pre>"},{"location":"sigmatek/salamander4/latency_reduction/IRQaffinity/IRQ_affinity/#batch-cat-irq-smp_affinity","title":"Batch cat IRQ smp_affinity","text":"<pre><code>cat /proc/irq/0/smp_affinity   # -&gt; fffff\ncat /proc/irq/2/smp_affinity   # -&gt; fffff             \ncat /proc/irq/3/smp_affinity   # -&gt; fffff             \ncat /proc/irq/4/smp_affinity   # -&gt; fffff            \ncat /proc/irq/5/smp_affinity   # -&gt; fffff             \ncat /proc/irq/6/smp_affinity   # -&gt; fffff            \ncat /proc/irq/7/smp_affinity   # -&gt; fffff            \ncat /proc/irq/10/smp_affinity  # -&gt; fffff              \ncat /proc/irq/11/smp_affinity  # -&gt; fffff            \ncat /proc/irq/12/smp_affinity  # -&gt; fffff            \ncat /proc/irq/13/smp_affinity  # -&gt; fffff              \ncat /proc/irq/15/smp_affinity # -&gt; fffff              \ncat /proc/irq/133/smp_affinity # -&gt; fffff              \ncat /proc/irq/172/smp_affinity # -&gt; 80000              \ncat /proc/irq/173/smp_affinity # -&gt; fffff              \ncat /proc/irq/189/smp_affinity # -&gt; 80000  \ncat /proc/irq/191/smp_affinity # -&gt; fffff              \n</code></pre>"},{"location":"sigmatek/salamander4/latency_reduction/IRQaffinity/IRQ_affinity/#batch-change-irq-smp_affinity-of-fffff","title":"Batch change IRQ smp_affinity of fffff","text":"<pre><code>sudo echo 7ffff &gt; /proc/irq/0/smp_affinity\nsudo echo 7ffff &gt; /proc/irq/2/smp_affinity  # stays fffff\nsudo echo 7ffff &gt; /proc/irq/3/smp_affinity\nsudo echo 7ffff &gt; /proc/irq/4/smp_affinity\nsudo echo 7ffff &gt; /proc/irq/5/smp_affinity\nsudo echo 7ffff &gt; /proc/irq/6/smp_affinity\nsudo echo 7ffff &gt; /proc/irq/7/smp_affinity\nsudo echo 7ffff &gt; /proc/irq/10/smp_affinity\nsudo echo 7ffff &gt; /proc/irq/11/smp_affinity\nsudo echo 7ffff &gt; /proc/irq/12/smp_affinity\nsudo echo 7ffff &gt; /proc/irq/13/smp_affinity\nsudo echo 7ffff &gt; /proc/irq/15/smp_affinity\nsudo echo 7ffff &gt; /proc/irq/133/smp_affinity    # stays 80000\nsudo echo 7ffff &gt; /proc/irq/172/smp_affinity    # stays 80000\nsudo echo 7ffff &gt; /proc/irq/173/smp_affinity    # stays fffff\nsudo echo 7ffff &gt; /proc/irq/189/smp_affinity    # stays fffff\nsudo echo 7ffff &gt; /proc/irq/191/smp_affinity    # stays fffff\n</code></pre>"},{"location":"sigmatek/salamander4/latency_reduction/IRQaffinity/IRQ_affinity/#could-not-be-changed","title":"COULD NOT BE CHANGED","text":"<pre><code>2\n172\n173\n189\n191\n</code></pre>"},{"location":"sigmatek/salamander4/latency_reduction/IRQaffinity/IRQ_affinity/#values","title":"VALUES","text":"<pre><code>cat /proc/irq/2/smp_affinity    #-&gt; fffff\ncat /proc/irq/172/smp_affinity  #-&gt; 80000\ncat /proc/irq/173/smp_affinity  #-&gt; 80000\ncat /proc/irq/189/smp_affinity  #-&gt; fffff\ncat /proc/irq/191/smp_affinity  #-&gt; fffff\n</code></pre>"},{"location":"sigmatek/salamander4/latency_reduction/IRQaffinity/table_CPU_IRQ/","title":"table CPU IRQ","text":"0 1 2 3 4 5 6 7 8 9 10 11 12 13 0 x 1 x x x x x x x x x x x x 2 x 3 x 4 x 5 x 6 x 7 x 8 x x x x x x x x x x x x 9 x x x x x x x x x x x x 10 x 11 x 12 x 13 x 14 x x x x x x x x x x x x 15 x 16 x x x x x x x x x x x x 19 x x x x x x x x x x x x 26 x x x x x x x x x x x x 27 x 40 x 120 x x x x x x x x x x x x 121 x x x x x x x x x x x x 122 x x x x 123 x x x x 124 x 125 x x x x 126 x 127 x x x x 129 x 130 x x x x 131 x 132 x 133 x 134 x 135 x 150 x 151 x 152 x 153 x 154 x 155 x 156 x 157 x 158 x 159 x 160 x 161 x 162 x 163 x 164 x 165 x 166 x 167 x 168 x 169 x 170 x 171 x 172 x 173 x 174 x 175 x 176 x 177 x 178 x 179 x 180 x 181 x 182 x x x x x x x x x x x x 183 x 187 x"},{"location":"sigmatek/salamander4/latency_reduction/kernel-patch/kernel-patch/","title":"Linux kernel patch","text":"<p>The Linux Kernel Archives </p> <p>See all kernels on system <pre><code>dpkg --get-selections | grep linux-image\n</code></pre> Remove unused kernel <pre><code>sudo apt remove --purge linux-image-&lt;uname-r&gt;\nsudo apt-get purge linux-image-&lt;uname-r&gt;\n</code></pre></p> <p>Kernel Basic - \u2705 Kernel Basics - \u2705 How to remove an old Linux kernel - \u2705 How to Remove Old Kernel in Kali Linux </p> <p>Real-time kernel - \u2705 Introduction to Realtime Linux - \u2705 An introduction to real-time Linux - \u2705 Kernel Recipes 2016 - Understanding a Real-Time System Steven Rostedt - \u2705 Ubuntu Pro Realtime Kernel Performance Comparison (2023) - 2. Kernel Configuration - Building a Custom Linux Kernel - A Checklist for Writing Linux Real-Time Applications - Finding Sources of Latency on your Linux System - Steven Rostedt, VMware</p> <p>Patch - \u2705 Applying the Realtime patch to the Linux kernel </p>"},{"location":"sigmatek/salamander4/latency_reduction/kernel-patch/kernel-patch/#kernel-patch-proceedure","title":"Kernel Patch Proceedure","text":"<p>Download Linux kernel and patch Gunzip the patch <pre><code>gunzip patch-*\n</code></pre> Patch the kernel source code <pre><code>patch -R -p1 &lt; ../patch-*\n</code></pre> Customize the configuration <pre><code>sudo make menuconfig\n</code></pre> Compile the kernel by using multiple cores. $(nproc) returns the number of processing units available.  <pre><code>make -j$(nproc)\n</code></pre> Install the kernel and its modules to the appropriate system directories. <pre><code>sudo make modules_install install \n</code></pre> Update the bootloader <pre><code>sudo update-grub\n</code></pre> Reboot the system <pre><code>sudo reboot \n</code></pre> This is the output  <pre><code>$ uname -a\nLinux pamhal 6.8.0-rt7 #1 SMP PREEMPT_RT Mon Mar 11 13:12:31 CET 2024 x86_64 x86_64 x86_64 GNU/Linux\n</code></pre></p>"},{"location":"sigmatek/salamander4/latency_reduction/kernel-patch/kernel-patch/#useful-stuff","title":"Useful stuff","text":"<p>qemu-optimization </p>"},{"location":"sigmatek/trace-cmd/kernelshark/","title":"Kernelshark","text":""},{"location":"sigmatek/trace-cmd/kernelshark/#kernelshark","title":"Kernelshark","text":"<p>kernelshark.org </p>"},{"location":"sigmatek/trace-cmd/kernelshark/#documentation","title":"Documentation","text":"<p>kernelshark/documentation</p>"},{"location":"sigmatek/trace-cmd/kernelshark/#usage-kernelshark","title":"Usage kernelshark","text":"<p>File trace.dat contains no data</p> <p>Host only <pre><code>sudo trace-cmd record -e kvm:kvm_entry -e kvm:kvm_exit\n</code></pre></p> <p>Host and Guest track all both <pre><code>sudo trace-cmd record -e all -A @3:823 --name Salamander4 -e all\n</code></pre></p> <p>Host and Guest track kvm, sched, irq, irq_vectors <pre><code>sudo trace-cmd record -e kvm -e sched -e irq -e irq_vectors -A @3:823 --name Salamander4 -e all ssh root@192.168.51 'ls -lR . &gt; /dev/null'\n</code></pre></p> <p>Host and Guest track kvm_entry and kvm_exit with ssh to guest <pre><code>sudo trace-cmd record -e kvm:kvm_entry -e kvm:kvm_exit -A @3:823 --name Salamander4 -e all ssh root@192.168.1.7851 'ls -lR . &gt; /dev/null'\n</code></pre></p> <p>Host and Guest track kvm_entry and kvm_exit <pre><code>sudo trace-cmd record -e kvm:kvm_entry -e kvm:kvm_exit -A @3:823 --name Salamander4 -e all\n</code></pre></p> <p>After trace-cmd raw <pre><code>trace-cmd report\n</code></pre></p> <p>After trace-cmd Salamander4 <pre><code>trace-cmd report --cpu 19 &gt; host_report.txt\n</code></pre></p> <p>After trace-cmd Salamander4 <pre><code>trace-cmd report -i trace-Salamander4.dat &gt; guest_report.txt\n</code></pre></p> <p>After trace-cmd kernelshark <pre><code>sudo trace-cmd convert -i trace.dat -o trace_v6.dat --file-version 6 --compression none\nsudo rm trace.dat\nmv trace_v6.dat trace.dat\nsudo trace-cmd convert -i trace-Salamander4.dat -o trace_v6.dat --file-version 6 --compression none\nsudo rm trace-Salamander4.dat\nmv trace_v6.dat trace-Salamander4.dat\nkernelshark\n</code></pre></p>"},{"location":"sigmatek/trace-cmd/kvm_exits/","title":"Kvm exits","text":""},{"location":"sigmatek/trace-cmd/kvm_exits/#kvm-exit-reasons","title":"KVM Exit Reasons","text":"Exit Reason Description APIC_WRITE Triggered when the guest writes to its Advanced Programmable Interrupt Controller (APIC). EXTERNAL_INTERRUPT Triggered when an external hardware interrupt occurs, usually caused by hardware devices signaling the host\u2019s CPU. HLT Triggered when the guest executes the HLT instruction, halting the CPU until the next external interrupt is fired. EPT_MISCONFIG Triggered due to a misconfiguration in the Extended Page Tables (EPT), a memory management feature in modern CPUs. PREEMPTION_TIMER Triggered when the preemption timer of the host expires, related to the host\u2019s scheduling of the guest. PAUSE_INSTRUCTION Triggered when the PAUSE instruction is executed, used in spinlock loops to improve performance and reduce power consumption. EPT_VIOLATION Triggered when a guest access to a page would result in a violation of the EPT permission settings. IO_INSTRUCTION Triggered when the guest executes an I/O instruction, such as IN or OUT. EOI_INDUCED Triggered when an end-of-interrupt (EOI) signal is sent to the APIC. MSR_READ Triggered when the guest reads from a Model-Specific Register (MSR). CPUID Triggered when the guest executes the CPUID instruction, used to identify the processor."},{"location":"sigmatek/trace-cmd/kvm_exits/#apic_write","title":"APIC_WRITE","text":"<ul> <li>Guest Makes a Request: A process in the guest (the virtual machine) makes a request, such as a read or write operation to a device.</li> <li>Hypervisor Intercepts the Request: The hypervisor (the host system) intercepts this request. The guest does not communicate directly with the hardware.</li> <li>Hypervisor Handles the Request: The hypervisor communicates with the actual hardware to handle the request.</li> <li>Device Sends an Interrupt: When the requested operation is complete (for example, data is ready to be sent back to the guest), the device sends an interrupt signal.</li> <li>Hypervisor Receives the Interrupt: This interrupt is first received by the hypervisor.</li> <li>Hypervisor Creates a Guest Interrupt: The hypervisor then creates a \u201cguest interrupt\u201d which is delivered to the guest when it is next scheduled to run.</li> <li>Guest Handles the Interrupt: This guest interrupt triggers the appropriate handler in the guest to process the incoming data or handle the completed operation.</li> </ul> <p>In the context of APIC virtualization, the APIC (Advanced Programmable Interrupt Controller) is virtualized by the hypervisor. This means that when the guest tries to interact with the APIC, it\u2019s actually interacting with a virtual representation of the APIC provided by the hypervisor. This allows the hypervisor to maintain control over the hardware and manage the delivery of interrupts to the guests.</p> <p>terenceli.github terenceli.github/apicv terenceli.github/kvm-performance Intel APIC Virtualization Technology</p>"},{"location":"sigmatek/trace-cmd/kvm_exits/#apic-virtualization-apicv","title":"APIC Virtualization (APICv)","text":"<p>Newer Intel processors offer hardware virtualization of the Advanced Programmable Interrupt Controller (APICv). APICv improves virtualized AMD64 and Intel 64 guest performance by allowing the guest to directly access the APIC, dramatically cutting down interrupt latencies and the number of virtual machine exits caused by the APIC. This feature is used by default in newer Intel processors and improves I/O performance.</p>"},{"location":"sigmatek/trace-cmd/trace-cmd/","title":"Trace cmd","text":""},{"location":"sigmatek/trace-cmd/trace-cmd/#tools","title":"Tools","text":"<p>trace-cmd.org</p>"},{"location":"sigmatek/trace-cmd/trace-cmd/#documentation","title":"Documentation","text":"<p>trace-cmd/documentation</p>"},{"location":"sigmatek/trace-cmd/trace-cmd/#usage-trace-cmd","title":"Usage trace-cmd","text":"<p>trace-cmd [COMMAND] ...</p> Command Description record Record a trace into a trace.dat file set Set a ftrace configuration parameter start Start tracing without recording into a file extract Extract a trace from the kernel stop Stop the kernel from recording trace data restart Restart the kernel trace data recording show Show the contents of the kernel tracing buffer reset Disable all kernel tracing and clear the trace buffers clear Clear the trace buffers report Read out the trace stored in a trace.dat file stream Start tracing and read the output directly profile Start profiling and read the output directly hist Show a histogram of the trace.dat information stat Show the status of the running tracing (ftrace) system split Parse a trace.dat file into smaller file(s) options List the plugin options available for trace-cmd report listen Listen on a network socket for trace clients agent Listen on a vsocket for trace clients setup-guest Create FIFOs for tracing guest VMs list List the available events, plugins, or options restore Restore a crashed record snapshot Take a snapshot of the running trace stack Output, enable, or disable kernel stack tracing check-events Parse trace event formats dump Read out the metadata from a trace file attach Attach a host and guest trace.dat file convert Convert a trace file to a different version"},{"location":"sigmatek/trace-cmd/trace-cmd/#usage-kernelshark","title":"Usage kernelshark","text":"<pre><code>kernelshark # host only  \nkernelshark trace.dat -a trace-Salamander4.dat #host with guest\n</code></pre>"},{"location":"sigmatek/trace-cmd/hardware/events/events_report_cpu0/","title":"Events report cpu0","text":"<p>Total count of all events: 427.904</p> Event Count rcu_utilization 41.928 sched_switch 16.586 cpu_idle 15.140 kmem_cache_alloc 14.445 writeback_mark_inode_dirty 13.821 irq_handler_entry 13.421 irq_handler_exit 13.421 mm_page_alloc 13.069 sched_stat_runtime 9.063 sched_wakeup 8.719 read_msr 8.376 kfree 7.947 kmem_cache_free 7.798 kmalloc 7.253 block_touch_buffer 7.214 ext4_mark_inode_dirty 7.179 ext4_fc_track_inode 7.178 writeback_dirty_inode_start 7.169 writeback_dirty_inode 7.169 ext4_journal_start 7.128 jbd2_handle_start 7.101 jbd2_handle_stats 7.101 ext4_es_lookup_extent_enter 6.717 ext4_es_lookup_extent_exit 6.717 mm_lru_insertion 6.658 block_dirty_buffer 6.652 writeback_dirty_page 6.652 mm_filemap_add_to_page_cache 6.641 ext4_da_write_begin 6.640 ext4_da_reserve_space 6.640 ext4_es_insert_delayed_block 6.640 ext4_da_write_end 6.640 mm_page_free 6.461 sched_waking 6.130 mm_page_alloc_zone_locked 6.094 irq_pipeline_entry 5.161 irq_pipeline_exit 5.161 hrtimer_cancel 5.073 hrtimer_start 5.070 hrtimer_expire_entry 4.855 hrtimer_expire_exit 4.855 cobalt_timer_start 4.795 cobalt_tick_shot 4.795 write_msr 4.795 local_timer_entry 4.794 cobalt_timer_expire 4.794 local_timer_exit 4.794 sys_exit 3.641 sys_enter 3.641 sched_wake_idle_without_ipi 2.909 tlb_flush 2.209 softirq_raise 1.624 softirq_entry 1.612 softirq_exit 1.612 rseq_update 1.453 x86_fpu_regs_deactivated 1.403 x86_fpu_regs_activated 1.101 sys_enter_splice 830 sys_exit_splice 829 hrtimer_init 822 sys_enter_clock_nanosleep 484 sys_exit_clock_nanosleep 484 global_dirty_state 479 sched_migrate_task 443 sys_enter_pselect6 421 sys_exit_pselect6 421 i915_reg_rw 347 sys_enter_recvmsg 322 sys_exit_recvmsg 322 sys_exit_epoll_wait 299 sys_enter_epoll_wait 299 sys_exit_futex 249 sys_enter_futex 249 workqueue_queue_work 244 workqueue_activate_work 244 mm_page_free_batched 236 skb_copy_datagram_iovec 171 consume_skb 170 sys_exit_poll 170 sys_enter_poll 170 timer_cancel 164 workqueue_execute_start 163 workqueue_execute_end 163 kmalloc_node 161 mmap_lock_acquire_returned 144 kmem_cache_alloc_node 143 mmap_lock_start_locking 142 mmap_lock_released 142 timer_start 136 sys_enter_ioctl 136 sys_exit_ioctl 136 call_function_single_entry 119 call_function_single_exit 119 sys_enter_setitimer 112 itimer_state 112 sys_exit_setitimer 112 block_rq_complete 96 ata_qc_complete_done 94 scsi_dispatch_cmd_done 94 page_fault_user 92 ext4_es_cache_extent 91 timer_expire_entry 81 timer_expire_exit 81 timer_init 76 sys_enter_read 75 sys_exit_read 75 sys_enter_writev 72 sys_exit_writev 72 sys_enter_sendto 67 sys_exit_sendto 67 sys_exit_write 63 sys_enter_write 63 rpm_usage 52 rpm_resume 49 rpm_return_int 49 block_rq_issue 47 scsi_dispatch_cmd_start 47 ata_qc_issue 47 sys_enter_openat 46 sys_exit_openat 46 block_bio_remap 46 block_bio_queue 46 block_getrq 43 ext4_ext_map_blocks_enter 42 ext4_es_insert_extent 42 ext4_ext_map_blocks_exit 42 block_rq_insert 42 ext4_ext_show_extent 41 ext4_fc_track_range 41 dma_fence_signaled 36 i915_request_retire 36 writeback_single_inode_start 36 writeback_single_inode 36 writeback_start 35 writeback_queue_io 35 writeback_written 35 sb_mark_inode_writeback 34 block_plug 34 block_unplug 34 ext4_writepages 34 ext4_da_write_pages 34 ext4_da_write_pages_extent 34 ext4_request_blocks 34 ext4_allocate_blocks 34 ext4_da_update_reserve_space 34 ext4_writepages_result 34 writeback_write_inode_start 34 writeback_write_inode 34 ext4_mballoc_prealloc 33 writeback_dirty_inode_enqueue 29 dma_fence_init 27 sys_enter_madvise 27 sys_exit_madvise 27 reschedule_entry 25 reschedule_exit 25 dma_fence_enable_signal 23 dma_fence_destroy 23 drm_vblank_event 23 writeback_pages_written 20 writeback_wake_background 20 napi_poll 15 sys_enter_getrandom 14 sys_exit_getrandom 14 rss_stat 14 wbc_writepage 12 sb_clear_inode_writeback 10 i915_request_queue 9 i915_request_add 9 sys_enter_lseek 9 sys_exit_lseek 9 drm_vblank_event_delivered 9 sys_enter_newfstatat 7 sys_exit_newfstatat 7 netif_receive_skb 7 sys_enter_fcntl 7 sys_exit_fcntl 7 ext4_journal_start_reserved 7 ext4_ext_handle_unwritten_extents 7 napi_gro_receive_entry 6 napi_gro_receive_exit 6 sys_enter_close 6 sys_exit_close 6 sys_enter_mprotect 6 sys_exit_mprotect 6 sys_enter_rt_sigprocmask 6 sys_exit_rt_sigprocmask 6 sys_enter_recvfrom 6 sys_exit_recvfrom 6 mm_compaction_kcompactd_sleep 5 sched_process_wait 5 sys_enter_rt_sigaction 4 sys_exit_rt_sigaction 4 sys_enter_clock_gettime 4 sys_exit_clock_gettime 4 qdisc_dequeue 4 fib_table_lookup 4 kfree_skb 4 tcp_probe 3 block_bio_backmerge 3 sys_enter_pipe2 2 sys_exit_pipe2 2 intel_pipe_update_start 2 intel_pipe_update_vblank_evaded 2 intel_update_plane 2 intel_pipe_update_end 2 intel_frontbuffer_flush 2 intel_fbc_activate 2 intel_fbc_nuke 2 iomap_iter 2 fib6_table_lookup 2 sys_enter_epoll_ctl 2 sys_exit_epoll_ctl 2 tcp_rcv_space_adjust 2 sys_enter_mmap 2 vm_unmapped_area 2 sys_exit_mmap 2 sys_enter_munmap 2 sys_exit_munmap 2 sys_exit_ppoll 2 sys_enter_ppoll 2 page_fault_kernel 1 sys_exit_clone 1 sys_enter_set_robust_list 1 sys_exit_set_robust_list 1 ext4_request_inode 1 ext4_allocate_inode 1 ext4_fc_track_create 1 ext4_es_find_extent_range_enter 1 ext4_es_find_extent_range_exit 1 iomap_iter_dstmap 1 ext4_mb_new_inode_pa 1 ext4_mballoc_alloc 1 sys_enter_clone3 1 x86_fpu_copy_src 1 x86_fpu_copy_dst 1 task_newtask 1 sched_process_fork 1 sched_wakeup_new 1 sys_exit_clone3 1 sys_enter_socket 1 sys_exit_socket 1 sys_enter_connect 1 sys_exit_connect 1 net_dev_queue 1 net_dev_start_xmit 1 netif_rx_entry 1 netif_rx 1 netif_rx_exit 1 net_dev_xmit 1 sys_enter_dup 1 sys_exit_dup 1 sys_enter_sendmsg 1 sys_exit_sendmsg 1 signal_deliver 1 sys_enter_rt_sigreturn 1"},{"location":"sigmatek/trace-cmd/hardware/events/events_report_cpu1/","title":"Events report cpu1","text":"<p>Total count of all events: 874.588</p> Event Count cobalt_head_sysentry 90.902 cobalt_head_sysexit 89.642 cobalt_trace_pid 42.832 cobalt_synch_try_acquire 40.200 cobalt_synch_release 40.200 rcu_utilization 39.450 irq_handler_entry 23.029 irq_handler_exit 23.029 cobalt_schedule 16.807 cobalt_switch_context 16.789 sched_switch 15.423 x86_fpu_regs_deactivated 14.646 tlb_flush 12.781 x86_fpu_regs_activated 12.429 cobalt_timer_start 12.289 cpu_idle 12.265 cobalt_tick_shot 10.918 write_msr 10.918 sched_waking 10.659 cobalt_thread_resume 10.496 cobalt_thread_suspend 10.496 irq_pipeline_entry 10.266 irq_pipeline_exit 10.266 sys_enter 9.460 sys_exit 9.459 cobalt_synch_sleepon 9.236 cobalt_fd_ioctl 9.220 kmem_cache_alloc 8.630 cobalt_synch_flush 8.386 cobalt_driver_event_wait 8.386 read_msr 8.376 mm_page_alloc 8.089 sched_wakeup 8.070 kfree 8.016 writeback_mark_inode_dirty 7.998 sched_stat_runtime 7.230 cobalt_timer_stop 6.821 cobalt_timer_expire 5.833 local_timer_entry 5.832 local_timer_exit 5.832 hrtimer_start 5.660 hrtimer_cancel 5.655 sched_wake_idle_without_ipi 5.532 hrtimer_expire_entry 5.532 hrtimer_expire_exit 5.532 kmem_cache_free 4.980 block_touch_buffer 4.424 mm_page_alloc_zone_locked 4.410 mm_lru_insertion 4.396 ext4_mark_inode_dirty 4.373 ext4_fc_track_inode 4.373 kmalloc 4.351 cobalt_driver_event_signal 4.201 jbd2_handle_start 4.193 jbd2_handle_stats 4.193 cobalt_driver_event_pulse 4.185 ext4_journal_start 4.166 writeback_dirty_inode_start 4.161 writeback_dirty_inode 4.161 mm_page_free 4.116 ext4_es_lookup_extent_enter 4.020 ext4_es_lookup_extent_exit 4.020 block_dirty_buffer 3.837 writeback_dirty_page 3.837 mm_filemap_add_to_page_cache 3.827 ext4_da_write_begin 3.824 ext4_da_reserve_space 3.824 ext4_es_insert_delayed_block 3.824 ext4_da_write_end 3.824 rseq_update 3.271 softirq_raise 1.588 softirq_entry 1.586 softirq_exit 1.586 hrtimer_init 1.445 cobalt_shadow_gorelax 1.260 cobalt_lostage_request 1.260 cobalt_lostage_wakeup 1.260 cobalt_shadow_relaxed 1.260 cobalt_root_sysentry 1.260 cobalt_shadow_gohard 1.260 cobalt_shadow_hardened 1.260 cobalt_root_sysexit 1.260 cobalt_fd_recvmsg 834 cobalt_fd_ioctl_status 522 mm_page_free_batched 513 mm_filemap_delete_from_page_cache 512 cobalt_synch_wakeup 484 sys_exit_splice 479 sys_enter_splice 478 cobalt_fd_sendmsg 416 sys_exit_clock_nanosleep 386 sys_enter_clock_nanosleep 386 i915_reg_rw 381 cobalt_synch_forget 366 cobalt_fd_recvmsg_status 366 sched_migrate_task 365 timer_start 349 ext4_es_cache_extent 334 timer_cancel 315 global_dirty_state 307 timer_init 278 timer_expire_entry 270 timer_expire_exit 270 sys_enter_pselect6 242 sys_exit_pselect6 240 sys_enter_futex 237 sys_exit_futex 236 kmalloc_node 232 kmem_cache_alloc_node 160 consume_skb 155 sys_exit_poll 152 sys_enter_poll 152 call_function_single_entry 146 call_function_single_exit 146 workqueue_execute_start 144 workqueue_execute_end 144 sys_exit_epoll_wait 133 sys_enter_epoll_wait 133 ext4_ext_map_blocks_enter 130 ext4_ext_map_blocks_exit 130 ext4_es_insert_extent 130 ext4_fc_track_range 129 skb_copy_datagram_iovec 128 ext4_ext_show_extent 127 sys_enter_recvmsg 122 sys_exit_recvmsg 122 mmap_lock_acquire_returned 111 mmap_lock_released 110 mmap_lock_start_locking 109 sys_enter_ioctl 107 sys_exit_ioctl 107 page_fault_user 87 ext4_journal_start_reserved 78 ext4_ext_handle_unwritten_extents 78 sys_enter_sendto 70 sys_exit_sendto 70 block_bio_remap 67 block_bio_queue 67 napi_poll 66 sb_clear_inode_writeback 66 netif_receive_skb 61 workqueue_queue_work 60 workqueue_activate_work 60 napi_gro_receive_entry 59 napi_gro_receive_exit 59 fib_table_lookup 56 sys_enter_read 55 sys_exit_read 55 ext4_da_write_pages 51 ext4_da_write_pages_extent 51 ext4_request_blocks 51 ext4_allocate_blocks 51 ext4_da_update_reserve_space 51 sys_enter_setitimer 50 itimer_state 50 sys_exit_setitimer 50 block_getrq 47 block_rq_issue 47 scsi_dispatch_cmd_start 47 ata_qc_issue 47 block_plug 46 block_unplug 46 block_rq_insert 46 rpm_resume 42 rpm_return_int 42 writeback_start 42 writeback_queue_io 42 writeback_single_inode_start 42 ext4_writepages 42 sb_mark_inode_writeback 42 ext4_writepages_result 42 writeback_write_inode_start 42 writeback_write_inode 42 writeback_single_inode 42 writeback_written 42 ext4_mballoc_prealloc 39 sched_process_wait 36 rpm_usage 35 sys_enter_writev 34 sys_exit_writev 34 writeback_dirty_inode_enqueue 34 iomap_iter 32 kfree_skb 31 sys_enter_write 27 sys_exit_write 27 writeback_pages_written 26 neigh_update 23 neigh_update_done 23 reschedule_entry 22 reschedule_exit 22 block_bio_backmerge 20 iomap_iter_dstmap 16 cobalt_event_timedwait 16 ext4_mballoc_alloc 12 sys_enter_madvise 12 sys_exit_madvise 12 ext4_mb_new_inode_pa 11 dma_fence_destroy 11 sys_enter_getrandom 10 sys_exit_getrandom 10 dma_fence_init 9 i915_request_queue 9 i915_request_add 9 sys_enter_newfstatat 8 sys_exit_newfstatat 8 intel_pipe_update_start 7 intel_pipe_update_vblank_evaded 7 intel_update_plane 7 intel_pipe_update_end 7 intel_frontbuffer_flush 7 intel_fbc_activate 7 intel_fbc_nuke 7 sys_enter_rt_sigprocmask 5 sys_exit_rt_sigprocmask 5 sys_enter_openat 5 sys_exit_openat 5 sys_enter_close 5 sys_exit_close 5 sys_enter_mprotect 5 sys_exit_mprotect 5 sys_enter_getpid 4 sys_exit_getpid 4 sys_enter_fcntl 4 sys_exit_fcntl 4 dma_fence_enable_signal 4 writeback_wake_background 4 net_dev_queue 3 net_dev_start_xmit 3 net_dev_xmit 3 mm_compaction_kcompactd_sleep 3 rss_stat 3 signal_generate 3 sys_exit_ppoll 2 sys_enter_ppoll 2 sys_enter_pipe2 2 sys_exit_pipe2 2 jbd2_start_commit 2 jbd2_commit_locking 2 jbd2_commit_flushing 2 jbd2_commit_logging 2 jbd2_run_stats 2 jbd2_end_commit 2 sys_enter_clock_gettime 2 sys_exit_clock_gettime 2 sys_enter_lseek 2 sys_exit_lseek 2 netif_rx_entry 2 netif_rx 2 netif_rx_exit 2 tcp_probe 2 sys_enter_mmap 2 vm_unmapped_area 2 sys_exit_mmap 2 sys_enter_munmap 2 sys_exit_munmap 2 jbd2_checkpoint_stats 1 jbd2_drop_transaction 1 ext4_es_find_extent_range_enter 1 ext4_es_find_extent_range_exit 1 sys_exit_clone3 1 sys_enter_rseq 1 sys_exit_rseq 1 sys_enter_set_robust_list 1 sys_exit_set_robust_list 1 sys_enter_gettid 1 sys_exit_gettid 1 tcp_rcv_space_adjust 1 sys_enter_setpriority 1 sys_exit_setpriority 1 sys_enter_prctl 1 task_rename 1 sys_exit_prctl 1 sys_enter_ftruncate 1 sys_exit_ftruncate 1 sys_enter_fallocate 1 sys_exit_fallocate 1 sys_enter_unlink 1 sys_exit_unlink 1 sys_enter_sendmsg 1 sys_exit_sendmsg 1 mm_lru_activate 1"},{"location":"sigmatek/trace-cmd/hardware/tasks/tasks_report_cpu0/","title":"Tasks report cpu0","text":"<p>Total count of all tasks: 427.904</p> Task PID Count trace-cmd 651 215.631 \\&lt;idle&gt; 0 149.975 trace-cmd 650 20.920 ksoftirqd/0 14 9.886 DS_Project 485 5.886 X 395 4.220 kworker/u4:0 630 3.490 chromium-bin 526 2.076 irq/129-ahci[00 92 1.431 Chrome_ChildIOT 547 1.323 irq/128-i915 88 1.285 Chrome_ChildIOT 572 1.101 Compositor 580 1.056 kworker/0:1 28 1.050 DataService 482 1.019 chromium-bin 566 955 VizCompositorTh 548 851 Chrome_ChildIOT 534 707 ThreadPoolForeg 573 685 LE-Logger 394 670 Chrome_IOThread 515 625 cobalt_printf 420 491 xterm 467 374 rcu_preempt 15 256 LE-System 393 239 LRTMgr-Main 414 229 chromium-bin 496 188 ThreadPoolForeg 546 158 kworker/u5:0 68 152 irq/132-eth0-rx 476 124 CompositorTileW 585 110 kworker/0:1H 99 100 CompositorTileW 584 87 ServiceWorker N/A 82 ThreadPoolSingl 556 64 trace-cmd 649 54 sshd 612 54 chromium-bin 530 45 CompositorTileW 586 38 irq/134-eth0-tx 478 36 jbd2/sda2-8 112 36 kcompactd0 32 35 GpuWatchdog 543 34 init 1 31 DS_TCP_Conn_Svr 487 26 kworker/u4:3 97 19"},{"location":"sigmatek/trace-cmd/hardware/tasks/tasks_report_cpu1/","title":"Tasks report cpu1","text":"<p>Total count of all tasks: 874.588</p> Task PID Count \\&lt;...&gt; 449 286.721 \\&lt;idle&gt; 0 261.051 trace-cmd 650 120.255 \\&lt;...&gt; 429 58.286 LRT-Main 419 46.694 CLI:468 468 22.385 trace-cmd 651 19.477 ksoftirqd/1 22 11.420 kworker/u4:0 630 8.102 MainTaskLow:459 459 7.904 DS_Project 485 5.269 MainTaskHigh:46 460 4.459 chromium-bin 566 2.766 X 395 1.951 Chrome_IOThread 515 1.929 VizCompositorTh 548 1.835 LRTMgr-Main 414 1.810 LE-Logger 394 1.722 Compositor 580 1.582 kWorker-LRT 389 1.351 chromium-bin 526 1.239 irq/131-eth0-rx 475 1.013 Chrome_ChildIOT 572 843 LrtMgrCyclic:47 471 575 kworker/u5:0 68 563 Chrome_ChildIOT 547 522 rcu_preempt 15 496 \\&lt;...&gt; 425 425 chromium-bin 496 231 jbd2/sda2-8 112 197 kworker/1:1 29 170 ThreadPoolForeg 652 151 kworker/1:1H 66 143 ThreadPoolForeg 596 123 jbd2/sda4-8 132 122 xterm 467 116 TCP-Listen:462 462 113 MHD-connection 611 100 CompositorTileW 583 90 ThreadPoolForeg 546 63 ThreadPoolForeg 573 63 chromium-bin 550 57 sshd 612 53 CompositorTileW 586 50 ServiceWorker N/A 22 irq/133-eth0-tx 477 21 CompositorTileW 585 21 kcompactd0 32 21 kworker/u4:3 97 16"},{"location":"sigmatek/trace-cmd/virtualization/compare/","title":"Compare","text":""},{"location":"sigmatek/trace-cmd/virtualization/compare/#kvm_exit","title":"KVM_EXIT","text":"power_saver balanced performance"},{"location":"sigmatek/trace-cmd/virtualization/compare/#host","title":"Host","text":"power_saver balanced performance"},{"location":"sigmatek/trace-cmd/virtualization/compare/#guest","title":"Guest","text":"power_saver balanced performance"},{"location":"sigmatek/trace-cmd/virtualization/balanced/results_guest_report/","title":"Results guest report","text":"<p>Total count of all events: 203.883</p> Task PID Count \\&lt;idle&gt; 0 84.399 LRT-Main 328 33.551 trace-cmd 501 25.473 CLI:343 343 15.719 kthreadd 502 12.891 MainTaskLow:337 337 11.525 MainTaskHigh:33 338 5.489 \\&lt;...&gt; 336 5.346 LE-Logger 324 3.070 kworker/0:0 498 1.646 kWorker-LRT 318 1.581 LRTMgr-Main 325 957 cobalt_printf 329 713 LrtMgrCyclic:34 346 701 LE-System 322 315 TCP-Listen:340 340 130 rcu_preempt 15 123 kcompactd0 25 66 init 1 59 kworker/0:1 22 45 trace-cmd 499 31 kthreadd 2 25 kworker/u2:2 63 15 ksoftirqd/0 14 13"},{"location":"sigmatek/trace-cmd/virtualization/balanced/results_host_report/","title":"Results host report","text":"<p>Total count of all events: 230.726</p> Task PID Count qemu-system-x86 9878 149.789 \\&lt;idle&gt; 0 65.240 vhost-9870 9899 11.078 qemu-system-x86 9870 3.924 qemu-system-x86 9914 335 qemu-system-x86 9912 275 kworker/19:3 7883 82 migration/19 94 3"},{"location":"sigmatek/trace-cmd/virtualization/default/kvm_exit_default_results/","title":"Kvm exit default results","text":""},{"location":"sigmatek/trace-cmd/virtualization/default/kvm_exit_default_results/#kvm_exit_default","title":"kvm_exit_default","text":"<pre><code>Total exits: 14132.\n'APIC_WRITE': 8445 times\n'HLT': 3778 times\n'EPT_MISCONFIG': 1289 times\n'PREEMPTION_TIMER': 163 times\n'EXTERNAL_INTERRUPT': 207 times\n'IO_INSTRUCTION': 78 times\n'EOI_INDUCED': 38 times\n'EPT_VIOLATION': 90 times\n'PAUSE_INSTRUCTION': 33 times\n'CPUID': 10 times\n'MSR_READ': 1 times\n</code></pre>"},{"location":"sigmatek/trace-cmd/virtualization/normal/events/events_guest_report/","title":"Events guest report","text":"<p>Total count of all events: 217.015</p> Event Count rcu_utilization 16.042 cobalt_trace_pid 9.967 cobalt_timer_start 7.661 sched_switch 7.659 irq_handler_entry 7.335 irq_handler_exit 7.335 kfree 6.945 kmalloc 6.800 cobalt_tick_shot 6.750 tlb_flush 5.639 cpu_idle 5.596 hrtimer_cancel 4.982 hrtimer_start 4.982 x86_fpu_regs_deactivated 4.789 sys_exit 4.638 sys_enter 4.638 sched_waking 4.385 sched_wakeup 4.385 cobalt_schedule 4.304 cobalt_switch_context 4.303 cobalt_head_sysentry 4.251 sched_stat_runtime 4.119 sched_stat_wait 3.800 irq_pipeline_entry 3.605 irq_pipeline_exit 3.605 cobalt_head_sysexit 3.457 x86_fpu_regs_activated 3.388 local_timer_entry 2.852 local_timer_exit 2.852 cobalt_timer_stop 2.711 write_msr 2.448 rseq_update 2.292 cobalt_timer_expire 2.279 cobalt_thread_resume 2.154 cobalt_thread_suspend 2.154 workqueue_queue_work 2.135 workqueue_activate_work 2.135 workqueue_execute_start 2.135 workqueue_execute_end 2.134 sched_stat_sleep 1.905 tick_stop 1.840 virtio_transport_alloc_pkt 1.697 mm_page_alloc 1.606 mm_page_free 1.594 hrtimer_expire_entry 1.465 hrtimer_expire_exit 1.465 cobalt_fd_ioctl 1.357 hrtimer_init 1.127 sched_stat_blocked 1.007 cobalt_fd_recvmsg 907 cobalt_synch_sleepon 907 cobalt_synch_flush 906 cobalt_shadow_gorelax 794 cobalt_lostage_request 794 cobalt_lostage_wakeup 794 cobalt_shadow_relaxed 794 cobalt_root_sysentry 794 cobalt_shadow_gohard 794 cobalt_shadow_hardened 794 cobalt_synch_try_acquire 794 cobalt_root_sysexit 794 cobalt_synch_release 794 cobalt_synch_wakeup 513 cobalt_driver_event_signal 453 cobalt_driver_event_pulse 453 cobalt_thread_wait_period 453 cobalt_fd_ioctl_status 450 cobalt_fd_sendmsg 399 cobalt_synch_forget 394 cobalt_fd_recvmsg_status 394 softirq_raise 333 softirq_entry 333 softirq_exit 333 timer_cancel 319 timer_start 318 timer_expire_entry 310 timer_expire_exit 310 timer_init 227 sys_enter_splice 212 sys_exit_splice 212 sys_enter_pselect6 108 sys_exit_pselect6 107 kmem_cache_free 94 fib_table_lookup 88 mmap_lock_start_locking 64 mmap_lock_acquire_returned 64 mmap_lock_released 64 page_fault_user 62 kmem_cache_alloc 59 kmalloc_node 49 napi_gro_receive_entry 46 napi_gro_receive_exit 46 netif_receive_skb 46 napi_poll 46 sched_process_wait 45 consume_skb 43 virtio_transport_recv_pkt 34 neigh_update 34 neigh_update_done 34 mm_lru_insertion 15 mm_compaction_kcompactd_sleep 9 9p_protocol_dump 8 sys_enter_newfstatat 6 sys_exit_newfstatat 6 sys_enter_read 5 sys_exit_read 5 sys_enter_rt_sigaction 4 sys_exit_rt_sigaction 4 9p_client_req 4 9p_client_res 4 sys_enter_openat 3 sys_exit_openat 3 kfree_skb 3 page_fault_kernel 2 sys_enter_close 2 sys_exit_close 2 sys_enter_pipe2 2 sys_exit_pipe2 2 sys_enter_fcntl 2 sys_exit_fcntl 2 sys_exit_write 1 sys_exit_clone 1 sys_enter_set_robust_list 1 sys_exit_set_robust_list 1 sys_enter_accept 1 sys_exit_accept 1 qdisc_dequeue 1 read_msr 1 sys_enter_write 1"},{"location":"sigmatek/trace-cmd/virtualization/normal/events/events_host_report/","title":"Events host report","text":"<p>Total count of all events: 263.997</p> Event Count rcu_utilization 47.194 write_msr 31.593 read_msr 16.846 kvm_entry 13.174 kvm_exit 13.173 kvm_hv_timer_state 11.125 cpu_idle 10.843 sched_switch 8.633 kvm_apic 7.766 sched_stat_runtime 5.335 hrtimer_cancel 4.723 hrtimer_start 4.722 sched_waking 4.685 kvm_pv_tlb_flush 4.584 rseq_update 4.516 x86_fpu_regs_deactivated 4.475 hrtimer_expire_entry 4.423 hrtimer_expire_exit 4.423 local_timer_entry 4.400 local_timer_exit 4.400 sched_wakeup 4.256 kvm_apic_accept_irq 4.198 kvm_apicv_accept_irq 4.198 kvm_vcpu_wakeup 3.294 kvm_mmu_paging_element 2.055 kmem_cache_alloc 1.945 virtio_transport_recv_pkt 1.875 kmalloc 1.874 sk_data_ready 1.873 sys_exit 1.437 sys_enter 1.437 x86_fpu_regs_activated 1.368 thermal_apic_entry 1.194 thermal_apic_exit 1.194 kvm_halt_poll_ns 974 kvm_mmio 958 kfree 924 kvm_fpu 918 contention_begin 851 contention_end 851 kvm_msi_set_irq 749 kvm_fast_mmio 712 sys_enter_ioctl 709 sys_exit_ioctl 709 kvm_mmu_pagetable_walk 685 kvm_emulate_insn 685 vcpu_match_mmio 685 cpu_idle_miss 679 softirq_raise 656 softirq_entry 656 softirq_exit 656 csd_queue_cpu 497 kvm_userspace_exit 459 sched_wake_idle_without_ipi 456 tlb_flush 308 check_mmio_spte 261 handle_mmio_page_fault 261 kvm_set_irq 240 kvm_pic_set_irq 240 kvm_ioapic_set_irq 240 sys_exit_ppoll 230 sys_enter_ppoll 230 kmem_cache_free 217 sys_enter_read 187 sys_exit_read 187 hrtimer_init 183 sys_enter_futex 179 sys_exit_futex 179 csd_function_entry 171 csd_function_exit 171 ipi_send_cpu 166 kvm_wait_lapic_expire 165 kvm_page_fault 136 irq_work_entry 126 irq_work_exit 126 reschedule_entry 114 reschedule_exit 114 kvm_tdp_mmu_spte_changed 108 kvm_mmu_spte_requested 106 kvm_mmu_set_spte 106 call_function_single_entry 104 call_function_single_exit 104 consume_skb 102 mm_page_alloc_zone_locked 84 mm_page_alloc 82 kvm_pio 78 sys_enter_write 74 sys_exit_write 74 skb_copy_datagram_iovec 60 kvm_eoi 51 kvm_ack_irq 51 tick_stop 49 mm_lru_insertion 45 mmap_lock_start_locking 35 mmap_lock_acquire_returned 35 ma_read 35 mmap_lock_released 35 sched_migrate_task 34 kvm_unmap_hva_range 32 kvm_set_spte_hva 32 kvm_ple_window_update 30 mm_filemap_add_to_page_cache 26 sys_enter_openat 15 sys_exit_openat 15 sys_enter_newfstatat 15 sys_exit_newfstatat 15 sys_enter_close 15 sys_exit_close 15 timer_cancel 14 timer_expire_entry 14 timer_expire_exit 14 timer_start 14 workqueue_queue_work 13 workqueue_activate_work 13 workqueue_execute_start 13 workqueue_execute_end 13 sys_enter_fcntl 10 sys_exit_fcntl 10 kvm_cpuid 10 mm_page_free 7 kfree_skb 3 sys_enter_preadv 3 ext4_es_lookup_extent_enter 3 ext4_es_lookup_extent_exit 3 block_bio_remap 3 block_bio_queue 3 block_getrq 3 block_io_start 3 block_plug 3 nvme_setup_cmd 3 block_rq_issue 3 irq_handler_entry 3 nvme_sq 3 nvme_complete_rq 3 block_rq_complete 3 block_io_done 3 irq_handler_exit 3 sys_exit_preadv 3 page_fault_kernel 2 fast_page_fault 1 kvm_msr 1 kvm_mmu_get_page 1"},{"location":"sigmatek/trace-cmd/virtualization/normal/tasks/tasks_guest_report/","title":"Tasks guest report","text":"<p>Total count of all tasks: 217.015</p> Task PID Count \\&lt;idle&gt; 0 85.835 LRT-Main 328 33.201 trace-cmd 370 30.941 kworker/0:2 79 22.187 CLI:343 343 15.372 MainTaskLow:337 337 11.226 \\&lt;...&gt; 336 5.301 MainTaskHigh:33 338 5.260 LE-Logger 324 3.158 kWorker-LRT 318 1.499 LRTMgr-Main 325 952 LrtMgrCyclic:34 346 762 cobalt_printf 329 592 LE-System 322 291 TCP-Listen:340 340 116 rcu_preempt 15 106 kcompactd0 25 68 trace-cmd 368 43 init 1 31 ksoftirqd/0 14 18 kworker/u2:3 78 16 kworker/0:1 22 15 \\&lt;...&gt; 328 14 Debug N/A 11"},{"location":"sigmatek/trace-cmd/virtualization/normal/tasks/tasks_host_report/","title":"Tasks host report","text":"<p>Total count of all tasks: 263.997</p> Task PID Count qemu-system-x86 2947 168.997 \\&lt;idle&gt; 0 73.787 vhost-2918 3010 14.661 qemu-system-x86 2918 5.564 qemu-system-x86 6511 486 qemu-system-x86 6520 399 kworker/19:2 2942 97 migration/19 94 6"},{"location":"sigmatek/trace-cmd/virtualization/performance/results_guest_report/","title":"Results guest report","text":"<p>Total count of all events: 220.246</p> Task PID Count \\&lt;idle&gt; 0 88.305 LRT-Main 328 33.728 trace-cmd 505 30.664 kworker/0:2 502 21.889 CLI:343 343 15.633 MainTaskLow:337 337 11.576 MainTaskHigh:33 338 5.352 \\&lt;...&gt; 336 5.336 LE-Logger 324 2.928 kWorker-LRT 318 1.667 LRTMgr-Main 325 1.086 LrtMgrCyclic:34 346 712 cobalt_printf 329 608 LE-System 322 288 TCP-Listen:340 340 136 rcu_preempt 15 135 kcompactd0 25 70 kworker/0:1 22 47 init 1 31 trace-cmd 503 25 ksoftirqd/0 14 16 kworker/u2:2 63 14"},{"location":"sigmatek/trace-cmd/virtualization/performance/results_host_report/","title":"Results host report","text":"<p>Total count of all events: 262.536</p> Task PID Count qemu-system-x86 9878 167.324 \\&lt;idle&gt; 0 74.946 vhost-9870 9899 14.751 qemu-system-x86 9870 4.840 qemu-system-x86 9914 335 qemu-system-x86 9912 282 kworker/19:3 7883 55 migration/19 94 3"},{"location":"sigmatek/trace-cmd/virtualization/power_saver/results_guest_report/","title":"Results guest report","text":"<p>Total count of all events: 200.252</p> Task PID Count \\&lt;idle&gt; 0 74.499 LRT-Main 328 35.619 trace-cmd 497 23.619 CLI:343 343 16.670 MainTaskLow:337 337 12.730 kthreadd 498 11.216 LE-Logger 324 7.798 MainTaskHigh:33 338 5.759 \\&lt;...&gt; 336 5.593 kworker/0:2 460 1.707 kWorker-LRT 318 1.649 LRTMgr-Main 325 1.036 LrtMgrCyclic:34 346 794 cobalt_printf 329 719 LE-System 322 317 TCP-Listen:340 340 147 rcu_preempt 15 126 kcompactd0 25 102 init 1 31 kworker/0:1 22 28 kthreadd 2 26 trace-cmd 495 25 kworker/u2:2 63 22 ksoftirqd/0 14 20"},{"location":"sigmatek/trace-cmd/virtualization/power_saver/results_host_report/","title":"Results host report","text":"<p>Total count of all events: 217.343</p> Task PID Count qemu-system-x86 9878 141.785 \\&lt;idle&gt; 0 60.680 vhost-9870 9899 10.194 qemu-system-x86 9870 3.995 qemu-system-x86 9914 335 qemu-system-x86 9912 275 kworker/19:3 7883 73 migration/19 94 6"},{"location":"sigmatek/trace-cmd/virtualization/real-time/events/events_guest_report/","title":"Events guest report","text":"<p>Total count of all events: 253.987</p> Event Count rcu_utilization 23.138 sched_switch 11.077 cobalt_trace_pid 10.972 kmalloc 9.068 kfree 9.060 cobalt_timer_start 7.743 sched_stat_runtime 7.203 sched_stat_wait 7.191 irq_handler_entry 6.729 irq_handler_exit 6.729 sched_waking 6.274 sched_wakeup 6.274 tlb_flush 6.161 cobalt_tick_shot 5.945 x86_fpu_regs_deactivated 5.511 cpu_idle 5.380 sys_exit 5.190 sys_enter 5.190 hrtimer_cancel 4.842 hrtimer_start 4.842 cobalt_schedule 4.736 cobalt_switch_context 4.736 cobalt_head_sysentry 4.679 x86_fpu_regs_activated 4.102 write_msr 3.886 cobalt_head_sysexit 3.806 irq_pipeline_entry 3.061 irq_pipeline_exit 3.061 cobalt_timer_stop 2.978 local_timer_entry 2.729 local_timer_exit 2.729 workqueue_queue_work 2.626 workqueue_activate_work 2.626 workqueue_execute_start 2.626 workqueue_execute_end 2.626 rseq_update 2.613 sched_stat_blocked 2.608 cobalt_thread_resume 2.373 cobalt_thread_suspend 2.373 cobalt_timer_expire 2.149 virtio_transport_alloc_pkt 2.065 sched_stat_sleep 2.052 mm_page_alloc 1.974 mm_page_free 1.963 hrtimer_expire_entry 1.682 hrtimer_expire_exit 1.682 tick_stop 1.681 cobalt_fd_ioctl 1.492 hrtimer_init 1.238 cobalt_fd_recvmsg 1.000 cobalt_synch_sleepon 1.000 cobalt_synch_flush 986 cobalt_shadow_gorelax 873 cobalt_lostage_request 873 cobalt_lostage_wakeup 873 cobalt_shadow_relaxed 873 cobalt_root_sysentry 873 cobalt_shadow_gohard 873 cobalt_shadow_hardened 873 cobalt_synch_try_acquire 873 cobalt_root_sysexit 873 cobalt_synch_release 873 cobalt_synch_wakeup 567 cobalt_thread_wait_period 500 cobalt_driver_event_signal 493 cobalt_driver_event_pulse 493 cobalt_fd_ioctl_status 492 cobalt_fd_sendmsg 441 cobalt_synch_forget 433 cobalt_fd_recvmsg_status 433 softirq_raise 379 softirq_entry 379 softirq_exit 379 timer_cancel 364 timer_start 361 timer_expire_entry 345 timer_expire_exit 345 sys_enter_splice 258 sys_exit_splice 258 timer_init 257 virtio_transport_recv_pkt 246 sys_enter_pselect6 132 sys_exit_pselect6 131 kmem_cache_free 125 kmem_cache_alloc 96 fib_table_lookup 68 mmap_lock_start_locking 66 mmap_lock_acquire_returned 66 mmap_lock_released 66 page_fault_user 64 sched_process_wait 51 kmalloc_node 42 napi_gro_receive_entry 39 napi_gro_receive_exit 39 netif_receive_skb 39 napi_poll 36 consume_skb 32 neigh_update 27 neigh_update_done 27 9p_protocol_dump 24 sys_enter_futex 21 sys_exit_futex 21 mm_lru_insertion 15 sys_enter_read 12 sys_exit_read 12 9p_client_req 12 9p_client_res 12 mm_compaction_kcompactd_sleep 11 sys_enter_newfstatat 9 sys_exit_newfstatat 9 sys_exit_write 8 sys_enter_write 8 cobalt_thread_missed_period 7 console 7 kfree_skb 7 sys_enter_rt_sigaction 4 sys_exit_rt_sigaction 4 sys_enter_openat 3 sys_exit_openat 3 page_fault_kernel 2 sys_enter_close 2 sys_exit_close 2 sys_enter_pipe2 2 sys_exit_pipe2 2 sys_enter_fcntl 2 sys_exit_fcntl 2 sys_exit_clone 1 sys_enter_set_robust_list 1 sys_exit_set_robust_list 1 sys_enter_accept 1 sys_exit_accept 1 rss_stat 1 qdisc_dequeue 1 read_msr 1"},{"location":"sigmatek/trace-cmd/virtualization/real-time/events/events_host_report/","title":"Events host report","text":"<p>Total count of all events: 518.058</p> Event Count preempt_enable 104.057 preempt_disable 104.057 rcu_utilization 48.416 write_msr 39.044 read_msr 14.444 kvm_apic 14.296 kvm_entry 13.999 kvm_exit 13.999 kvm_hv_timer_state 10.615 sys_exit 8.649 sys_enter 8.649 cpu_idle 8.268 sched_switch 8.010 kfree 7.041 sys_enter_ioctl 6.996 sys_exit_ioctl 6.996 kvm_pv_tlb_flush 5.779 x86_fpu_regs_activated 5.474 kvm_fpu 5.182 sched_waking 4.976 sched_wakeup 4.976 hrtimer_cancel 4.954 hrtimer_start 4.954 kvm_set_irq 4.340 kvm_pic_set_irq 4.340 kvm_ioapic_set_irq 4.340 hrtimer_expire_entry 4.084 hrtimer_expire_exit 4.084 local_timer_entry 3.883 local_timer_exit 3.883 kvm_apic_accept_irq 3.435 rseq_update 3.383 x86_fpu_regs_deactivated 3.368 kvm_vcpu_wakeup 3.210 kvm_userspace_exit 2.591 kvm_pio 2.158 kvm_mmu_paging_element 2.082 sys_enter_writev 1.024 sys_exit_writev 1.024 kvm_mmio 1.014 kvm_halt_poll_ns 991 workqueue_queue_work 920 workqueue_activate_work 920 kvm_mmu_pagetable_walk 694 kvm_emulate_insn 694 vcpu_match_mmio 694 kmalloc 644 tlb_flush 642 kvm_wait_lapic_expire 423 sched_wake_idle_without_ipi 365 sched_stat_runtime 328 tick_stop 261 check_mmio_spte 236 handle_mmio_page_fault 236 sys_enter_read 233 sys_exit_read 233 kvm_fast_mmio 224 irq_work_entry 219 irq_work_exit 219 thermal_apic_entry 203 thermal_apic_exit 203 sys_exit_ppoll 197 sys_enter_ppoll 197 hrtimer_init 159 kmem_cache_free 154 kmalloc_node 104 sys_enter_write 85 sys_exit_write 85 sched_pi_setprio 85 kmem_cache_alloc 81 skb_copy_datagram_iovec 73 consume_skb 73 softirq_raise 48 sys_enter_futex 48 sys_exit_futex 48 softirq_entry 47 timer_cancel 47 timer_expire_entry 47 timer_expire_exit 47 softirq_exit 47 workqueue_execute_start 47 workqueue_execute_end 47 timer_start 45 kvm_eoi 44 kvm_ack_irq 44 mm_lru_insertion 30 mm_page_alloc 26 mm_filemap_add_to_page_cache 26 writeback_mark_inode_dirty 18 writeback_dirty_inode_start 16 ext4_journal_start 16 jbd2_handle_start 16 ext4_mark_inode_dirty 16 block_touch_buffer 16 ext4_fc_track_inode 16 jbd2_handle_stats 16 writeback_dirty_inode 16 sys_enter_openat 15 sys_exit_openat 15 sys_enter_newfstatat 15 sys_exit_newfstatat 15 sys_enter_close 15 sys_exit_close 15 sched_migrate_task 15 kvm_ple_window_update 14 kvm_msi_set_irq 12 sys_enter_fcntl 10 sys_exit_fcntl 10 kvm_cpuid 10 sys_enter_pwritev 8 ext4_da_write_begin 8 ext4_da_write_end 8 block_dirty_buffer 8 sys_exit_pwritev 8 reschedule_entry 7 reschedule_exit 7 sys_enter_preadv 3 ext4_es_lookup_extent_enter 3 ext4_es_lookup_extent_exit 3 block_bio_remap 3 block_bio_queue 3 block_getrq 3 block_plug 3 block_unplug 3 nvme_setup_cmd 3 block_rq_issue 3 irq_handler_entry 3 irq_handler_exit 3 nvme_sq 3 nvme_complete_rq 3 block_rq_complete 3 sys_exit_preadv 3 writeback_dirty_inode_enqueue 2 writeback_dirty_page 2 kvm_mmu_set_spte 2 kvm_msr 1 call_function_single_entry 1 call_function_single_exit 1 kvm_page_fault 1 fast_page_fault 1 kvm_mmu_spte_requested 1"},{"location":"sigmatek/trace-cmd/virtualization/real-time/tasks/tasks_guest_report/","title":"Tasks guest report","text":"<p>Total count of all tasks: 253.987</p> Task PID Count \\&lt;idle&gt; 0 82.512 trace-cmd 369 47.374 LRT-Main 331 36.896 kworker/0:1 22 30.447 CLI:346 346 17.730 MainTaskLow:340 340 13.331 LE-Logger 326 7.968 MainTaskHigh:34 341 6.118 \\&lt;...&gt; 339 5.879 kWorker-LRT 321 1.665 LRTMgr-Main 328 1.110 LrtMgrCyclic:34 349 826 cobalt_printf 332 680 LE-System 325 370 rs:main N/A 300 rcu_preempt 15 216 in:imklog 311 147 TCP-Listen:343 343 127 kcompactd0 25 89 init 1 74 ksoftirqd/0 14 31 trace-cmd 367 29 kworker/u2:0 9 24 kworker/0:3 155 23 \\&lt;...&gt; 331 13 kworker/0:1H 58 8"},{"location":"sigmatek/trace-cmd/virtualization/real-time/tasks/tasks_host_report/","title":"Tasks host report","text":"<p>Total count of all tasks: 518.058</p> Task PID Count qemu-system-x86 3161 415.995 \\&lt;idle&gt; 0 58.354 qemu-system-x86 2839 19.499 rcuc/19 172 11.333 irq_work/19 170 4.585 qemu-system-x86 2861 2.637 qemu-system-x86 6446 2.353 kworker/19:3 3162 1.825 ksoftirqd/19 173 838 irq/172-nvme0q2 462 591 migration/19 171 30 kworker/19:1H 3369 18"},{"location":"sigmatek/trace-cmd/virtualization/real-time-irq/events/events_guest_report/","title":"Events guest report","text":"<p>Total count of all events: 247.222</p> Event Count rcu_utilization 22.638 sched_switch 10.848 cobalt_trace_pid 10.521 kfree 8.762 kmalloc 8.622 cobalt_timer_start 7.648 sched_stat_wait 7.003 sched_stat_runtime 6.965 irq_handler_entry 6.700 irq_handler_exit 6.700 sched_waking 6.127 sched_wakeup 6.127 cobalt_tick_shot 5.974 tlb_flush 5.706 cpu_idle 5.340 x86_fpu_regs_deactivated 5.242 sys_exit 4.996 sys_enter 4.996 hrtimer_cancel 4.786 hrtimer_start 4.786 cobalt_schedule 4.543 cobalt_switch_context 4.541 cobalt_head_sysentry 4.490 x86_fpu_regs_activated 3.833 write_msr 3.826 cobalt_head_sysexit 3.650 irq_pipeline_entry 3.083 irq_pipeline_exit 3.083 cobalt_timer_stop 2.857 local_timer_entry 2.705 local_timer_exit 2.705 workqueue_queue_work 2.632 workqueue_activate_work 2.632 workqueue_execute_start 2.632 workqueue_execute_end 2.632 sched_stat_blocked 2.577 rseq_update 2.510 cobalt_thread_resume 2.277 cobalt_thread_suspend 2.277 cobalt_timer_expire 2.124 virtio_transport_alloc_pkt 2.001 sched_stat_sleep 1.997 mm_page_alloc 1.908 mm_page_free 1.899 tick_stop 1.672 hrtimer_expire_entry 1.617 hrtimer_expire_exit 1.617 cobalt_fd_ioctl 1.433 hrtimer_init 1.192 cobalt_fd_recvmsg 957 cobalt_synch_sleepon 957 cobalt_synch_flush 942 cobalt_shadow_gorelax 840 cobalt_lostage_request 840 cobalt_lostage_wakeup 840 cobalt_shadow_relaxed 840 cobalt_root_sysentry 840 cobalt_shadow_gohard 840 cobalt_shadow_hardened 840 cobalt_synch_try_acquire 840 cobalt_root_sysexit 840 cobalt_synch_release 840 cobalt_synch_wakeup 540 cobalt_thread_wait_period 480 cobalt_fd_ioctl_status 476 cobalt_driver_event_signal 471 cobalt_driver_event_pulse 471 cobalt_fd_sendmsg 420 cobalt_synch_forget 417 cobalt_fd_recvmsg_status 417 softirq_raise 364 softirq_entry 364 softirq_exit 364 timer_cancel 349 timer_start 348 timer_expire_entry 332 timer_expire_exit 332 sys_enter_splice 250 sys_exit_splice 250 timer_init 247 virtio_transport_recv_pkt 232 sys_enter_pselect6 127 sys_exit_pselect6 126 kmem_cache_free 121 kmem_cache_alloc 98 mmap_lock_start_locking 65 mmap_lock_acquire_returned 65 mmap_lock_released 65 fib_table_lookup 65 page_fault_user 63 mm_page_alloc_zone_locked 63 sched_process_wait 50 kmalloc_node 37 napi_gro_receive_entry 34 napi_gro_receive_exit 34 netif_receive_skb 34 consume_skb 33 napi_poll 33 9p_protocol_dump 28 sys_enter_futex 27 sys_exit_futex 27 neigh_update 24 neigh_update_done 24 mm_lru_insertion 15 sys_enter_read 14 sys_exit_read 14 9p_client_req 14 9p_client_res 14 sys_exit_write 10 mm_compaction_kcompactd_sleep 10 sys_enter_write 10 cobalt_thread_missed_period 9 console 9 sys_enter_newfstatat 6 sys_exit_newfstatat 6 sys_enter_rt_sigaction 4 sys_exit_rt_sigaction 4 sys_enter_openat 3 sys_exit_openat 3 page_fault_kernel 2 sys_enter_close 2 sys_exit_close 2 sys_enter_pipe2 2 sys_exit_pipe2 2 sys_enter_fcntl 2 sys_exit_fcntl 2 sys_exit_clone 1 sys_enter_set_robust_list 1 sys_exit_set_robust_list 1 sys_enter_accept 1 sys_exit_accept 1 read_msr 1 qdisc_dequeue 1 kfree_skb 1"},{"location":"sigmatek/trace-cmd/virtualization/real-time-irq/events/events_host_report/","title":"Events host report","text":"<p>Total count of all events: 566.436</p> Event Count preempt_enable 116.025 preempt_disable 116.025 rcu_utilization 49.852 write_msr 41.827 read_msr 16.612 kvm_entry 14.288 kvm_exit 14.287 kvm_apic 14.004 sys_exit 10.448 sys_enter 10.448 kvm_hv_timer_state 10.380 cpu_idle 9.118 sys_enter_ioctl 8.524 sys_exit_ioctl 8.524 kfree 8.453 sched_switch 8.198 x86_fpu_regs_activated 6.451 kvm_pv_tlb_flush 6.202 kvm_fpu 6.184 sched_waking 5.393 sched_wakeup 5.393 kvm_set_irq 5.352 kvm_pic_set_irq 5.352 kvm_ioapic_set_irq 5.352 hrtimer_cancel 4.720 hrtimer_start 4.719 hrtimer_expire_entry 4.080 hrtimer_expire_exit 4.080 local_timer_entry 4.059 local_timer_exit 4.059 kvm_apic_accept_irq 3.315 rseq_update 3.299 x86_fpu_regs_deactivated 3.284 kvm_vcpu_wakeup 3.131 kvm_userspace_exit 3.092 kvm_pio 2.678 kvm_mmu_paging_element 1.935 sys_enter_writev 1.280 sys_exit_writev 1.280 workqueue_queue_work 1.221 workqueue_activate_work 1.221 kvm_halt_poll_ns 994 kvm_mmio 952 kmalloc 804 sched_wake_idle_without_ipi 689 kvm_mmu_pagetable_walk 645 kvm_emulate_insn 645 vcpu_match_mmio 645 thermal_apic_entry 538 thermal_apic_exit 538 sched_stat_runtime 413 tlb_flush 402 kvm_wait_lapic_expire 373 kvm_fast_mmio 260 irq_work_entry 236 irq_work_exit 236 check_mmio_spte 213 handle_mmio_page_fault 213 sys_enter_read 204 sys_exit_read 204 kmem_cache_free 186 sys_exit_ppoll 180 sys_enter_ppoll 180 tick_stop 156 hrtimer_init 146 kmem_cache_alloc 144 kmalloc_node 99 sched_pi_setprio 93 sys_enter_write 83 sys_exit_write 83 mm_page_alloc_zone_locked 63 softirq_raise 58 workqueue_execute_start 57 workqueue_execute_end 57 skb_copy_datagram_iovec 57 consume_skb 57 sys_enter_futex 57 sys_exit_futex 57 timer_cancel 56 timer_expire_entry 56 timer_expire_exit 56 softirq_entry 55 softirq_exit 55 timer_start 55 mm_page_alloc 46 kvm_ple_window_update 41 kvm_eoi 39 kvm_ack_irq 39 mmap_lock_start_locking 39 mmap_lock_acquire_returned 39 mmap_lock_released 39 sched_migrate_task 30 mm_lru_insertion 30 sys_enter_rt_sigprocmask 26 sys_exit_rt_sigprocmask 26 mm_filemap_add_to_page_cache 26 writeback_mark_inode_dirty 21 writeback_dirty_inode_start 20 ext4_journal_start 20 jbd2_handle_start 20 ext4_mark_inode_dirty 20 block_touch_buffer 20 ext4_fc_track_inode 20 jbd2_handle_stats 20 writeback_dirty_inode 20 sys_enter_openat 15 sys_exit_openat 15 sys_enter_newfstatat 15 sys_exit_newfstatat 15 sys_enter_close 15 sys_exit_close 15 kvm_msi_set_irq 15 sys_enter_mmap 13 vm_unmapped_area 13 sys_exit_mmap 13 sys_enter_mprotect 13 sys_exit_mprotect 13 page_fault_user 13 sys_enter_pwritev 10 ext4_da_write_begin 10 ext4_da_write_end 10 block_dirty_buffer 10 sys_exit_pwritev 10 sys_enter_fcntl 10 sys_exit_fcntl 10 kvm_cpuid 10 reschedule_entry 5 reschedule_exit 5 mm_page_free 4 sys_enter_preadv 3 ext4_es_lookup_extent_enter 3 ext4_es_lookup_extent_exit 3 block_bio_remap 3 block_bio_queue 3 block_getrq 3 block_plug 3 block_unplug 3 nvme_setup_cmd 3 block_rq_issue 3 irq_handler_entry 3 irq_handler_exit 3 nvme_sq 3 nvme_complete_rq 3 block_rq_complete 3 sys_exit_preadv 3 kvm_msr 2 call_function_single_entry 1 call_function_single_exit 1 kvm_page_fault 1 fast_page_fault 1 kvm_mmu_spte_requested 1 kvm_mmu_set_spte 1 task_rename 1 sched_process_exit 1 x86_fpu_dropped 1 kvm_pvclock_update 1 sched_process_free 1 writeback_dirty_inode_enqueue 1 writeback_dirty_page 1"},{"location":"sigmatek/trace-cmd/virtualization/real-time-irq/tasks/tasks_guest_report/","title":"Tasks guest report","text":"<p>Total count of all tasks: 247.222</p> Task PID Count \\&lt;idle&gt; 0 82.048 trace-cmd 365 46.650 LRT-Main 330 35.439 kworker/0:1 22 29.844 CLI:345 345 16.816 MainTaskLow:339 339 12.764 LE-Logger 325 6.477 \\&lt;...&gt; 338 5.642 MainTaskHigh:34 340 5.632 kWorker-LRT 320 1.671 LRTMgr-Main 327 1.148 LrtMgrCyclic:34 348 827 cobalt_printf 331 642 LE-System 324 368 rs:main N/A 367 rcu_preempt 15 223 in:imklog 310 208 TCP-Listen:342 342 126 kcompactd0 25 119 kworker/0:2 79 113 init 1 31 trace-cmd 363 20 kworker/u2:2 63 19 ksoftirqd/0 14 15 \\&lt;...&gt; 330 13"},{"location":"sigmatek/trace-cmd/virtualization/real-time-irq/tasks/tasks_host_report/","title":"Tasks host report","text":"<p>Total count of all tasks: 566.436</p> Task PID Count qemu-system-x86 6212 456.963 \\&lt;idle&gt; 0 61.760 qemu-system-x86 6205 20.006 rcuc/19 172 13.159 irq_work/19 170 4.815 qemu-system-x86 6721 2.821 kworker/19:2 319 2.396 qemu-system-x86 6207 2.270 ksoftirqd/19 173 1.040 irq/172-nvme0q2 466 606 kworker/19:3 5821 570 migration/19 171 30"},{"location":"sigmatek/trace-cmd/virtualization/taskset/kvm_exit_taskset_results/","title":"Kvm exit taskset results","text":""},{"location":"sigmatek/trace-cmd/virtualization/taskset/kvm_exit_taskset_results/#kvm_exit","title":"kvm_exit","text":"<pre><code>Total exits: 122528.\n'APIC_WRITE': 60178 times\n'HLT': 53640 times\n'EPT_MISCONFIG': 3839 times\n'PREEMPTION_TIMER': 3239 times\n'EXTERNAL_INTERRUPT': 909 times\n'IO_INSTRUCTION': 565 times\n'EOI_INDUCED': 78 times\n'EPT_VIOLATION': 48 times\n'PAUSE_INSTRUCTION': 20 times\n'CPUID': 10 times\n'MSR_READ': 2 times\n</code></pre>"},{"location":"sigmatek/trace-cmd/virtualization/vapic/kvm_exit_vapic_results/","title":"Kvm exit vapic results","text":""},{"location":"sigmatek/trace-cmd/virtualization/vapic/kvm_exit_vapic_results/#kvm_exit","title":"kvm_exit","text":"<pre><code>Total exits: 1333.\n'MSR_WRITE': 820 times\n'APIC_WRITE': 0 times\n'HLT': 337 times\n'EPT_MISCONFIG': 108 times\n'PREEMPTION_TIMER': 39 times\n'EXTERNAL_INTERRUPT': 28 times\n'IO_INSTRUCTION': 0 times\n'EOI_INDUCED': 0 times\n'EPT_VIOLATION': 0 times\n'PAUSE_INSTRUCTION': 0 times\n'CPUID': 0 times\n'MSR_READ': 1 times\n</code></pre>"},{"location":"sigmatek/trace-cmd/working_trace-cmd/reinstall_trace-cmd/","title":"Reinstall trace cmd","text":"<pre><code> sudo rm /usr/local/bin/trace-cmd\n sudo rm /usr/bin/trace-cmd\n sudo rm /usr/local/lib64/libtracefs.so.1\n sudo rm /usr/local/lib64/libtraceevent.so.1\n\n sudo cp /home/sigma_ibo/Desktop/Masterarbeit/masterthesis-documentation/docs/sigmatek/trace-cmd/working_trace-cmd/trace-cmd /usr/local/bin/\n sudo cp /home/sigma_ibo/Desktop/Masterarbeit/masterthesis-documentation/docs/sigmatek/trace-cmd/working_trace-cmd/trace-cmd /usr/bin/\n sudo cp /home/sigma_ibo/Desktop/Masterarbeit/masterthesis-documentation/docs/sigmatek/trace-cmd/working_trace-cmd/libtracefs.so.1 /usr/local/lib64/\n sudo cp /home/sigma_ibo/Desktop/Masterarbeit/masterthesis-documentation/docs/sigmatek/trace-cmd/working_trace-cmd/libtraceevent.so.1 /usr/local/lib64/\n</code></pre>"},{"location":"sigmatek/yocto/after_bitbake/","title":"After bitbake","text":""},{"location":"sigmatek/yocto/after_bitbake/#enable-kernel-modules","title":"Enable kernel modules","text":"<p>Host-Guest Tutorial To have trace-cmd trace guests from the host, it is required that the guest is set up with vsocks. These are a virtual socket that lets the guest connect directly with the host. To do this, make sure that your guest kernel has the following configurations:</p> <p>CONFIG_VSOCKETS=m CONFIG_VHOST_VSOCK=m CONFIG_VIRTIO_VSOCKETS=m CONFIG_VIRTIO_VSOCKETS_COMMON=m CONFIG_VSOCKETS_DIAG=m CONFIG_VSOCKETS_LOOPBACK=m  </p> <p>And obviously have tracing enabled as well: CONFIG_TRACING=y CONFIG_FTRACE=y CONFIG_FUNCTION_TRACER=y CONFIG_FUNCTION_GRAPH_TRACER=y CONFIG_DYNAMIC_FTRACE=y CONFIG_DYNAMIC_FTRACE_WITH_REGS=y CONFIG_DYNAMIC_FTRACE_WITH_DIRECT_CALLS=y CONFIG_DYNAMIC_FTRACE_WITH_ARGS=y CONFIG_SCHED_TRACER=y CONFIG_FTRACE_SYSCALLS=y CONFIG_TRACER_SNAPSHOT=y CONFIG_KPROBE_EVENTS=y CONFIG_UPROBE_EVENTS=y CONFIG_BPF_EVENTS=y CONFIG_DYNAMIC_EVENTS=y CONFIG_PROBE_EVENTS=y CONFIG_SYNTH_EVENTS=y CONFIG_HIST_TRIGGERS=y  </p> <p>VirtioVsock</p>"},{"location":"sigmatek/yocto/after_bitbake/#bitbake","title":"bitbake","text":"<pre><code>../init.sh -b build -m sigmatek-core2 -d salamander\nbitbake salamander-image -k\n</code></pre>"},{"location":"sigmatek/yocto/after_bitbake/#qemu-script","title":"QEMU script","text":"<p>qemu_def_3hugepages_cmdline.sh</p>"},{"location":"sigmatek/yocto/after_bitbake/#scp-ipk-to-salamander4-and-install","title":"scp .ipk to Salamander4 and install","text":"<p>When you run bitbake xxx, the output of the build process, including any generated .ipk files, is typically stored in the tmp/deploy/ipk/ directory within your build directory1. The exact location can depend on your configuration and the specific recipe you\u2019re building.</p> <p>The .ipk files are package files used by opkg, a lightweight package management system. These files are created when you build a recipe that includes packaging steps. <pre><code>cd ~/Develop/Yocto_local/salamander/salamander-core2/build/tmp/deploy/ipk/core2-64$ scp trace-cmd_2.9.1-r0_core2-64.ipk root@10.30.248.137:/home/root/bb\nopkg install trace-cmd_2.9.1-r0_core2-64.ipk\n</code></pre></p>"},{"location":"sigmatek/yocto/after_bitbake/#warning-remote-host-identification-has-changed","title":"WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!","text":"<p><pre><code>@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\nSomeone could be eavesdropping on you right now (man-in-the-middle attack)!\nIt is also possible that a host key has just been changed.\nThe fingerprint for the ED25519 key sent by the remote host is\nSHA256:R1FIDyOY4bzLdNIJ3CUgwFRRzZPiq4dHL/DA5YY3Bw8.\nPlease contact your system administrator.\nAdd correct host key in /home/sigma_ibo/.ssh/known_hosts to get rid of this message.\nOffending ED25519 key in /home/sigma_ibo/.ssh/known_hosts:12\n  remove with:\n  ssh-keygen -f \"/home/sigma_ibo/.ssh/known_hosts\" -R \"10.30.248.137\"\nHost key for 10.30.248.137 has changed and you have requested strict checking.\nHost key verification failed.\n</code></pre> It seems like the SSH host key for the server at 10.30.248.137 has changed, which is causing the connection to fail due to strict checking. This could happen for a few reasons, such as the server being reinstalled or the SSH service being reconfigured.</p> <p>You can resolve this issue by removing the old host key from your known_hosts file. The offending key is on line 12 of the file. You can remove it with the following command:</p> <p><pre><code>ssh-keygen -f \"/home/sigma_ibo/.ssh/known_hosts\" -R \"10.30.248.137\" # Salzburg\nssh-keygen -f \"/home/sigma_ibo/.ssh/known_hosts\" -R \"192.168.1.78\" # Wien\"\n</code></pre> This will remove the old key for 10.30.248.137 from your known_hosts file. The next time you connect, you should be prompted to accept the new host key.</p>"},{"location":"tools/NONkernel_threads/","title":"NONkernel threads","text":""},{"location":"tools/NONkernel_threads/#cpu-dependant-kernel-threads","title":"CPU dependant kernel threads","text":"Thread Count ksoftirqd 20 rcuc 20 migration 20 irq_work 20 idle_inject 20 cpuhp 20"},{"location":"tools/tools/","title":"Tools","text":""},{"location":"tools/tools/#kvm_stat","title":"kvm_stat","text":"<pre><code>sudo kvm_stat -s 1 -c -L test.csv\n</code></pre>"},{"location":"tools/tools/#bcc","title":"bcc","text":"<p>Clone bcc <pre><code>git clone https://github.com/iovisor/bcc\n</code></pre> Execute bcc <pre><code>cd /usr/share/bcc/tools &amp;&amp; sudo ./kvmexit 1\nsudo kvmexit 2 &gt; kvmexit.log\n</code></pre></p>"},{"location":"tools/tools/#rt-tester","title":"rt-tester","text":"<p>Clone rt-tester <pre><code>git clone https://github.com/AgileDevArt/rt-tester\n</code></pre> Execute rt-tester <pre><code>g++ rt-tester -o rt-tester \n./rt-tester\n</code></pre></p>"},{"location":"tools/bcc/install_bcc/","title":"Install bcc","text":"<p>Installing BCC from source:</p> <ol> <li> <p>Install the necessary dependencies: <pre><code>sudo apt-get install -y bpfcc-tools libbpfcc libbpfcc-dev linux-headers-$(uname -r)\n</code></pre> <pre><code>sudo apt install -y zip bison build-essential cmake flex git libedit-dev \\\n  libllvm14 llvm-14-dev libclang-14-dev python3 zlib1g-dev libelf-dev libfl-dev python3-setuptools \\\n  liblzma-dev libdebuginfod-dev arping netperf iperf\n</code></pre></p> </li> <li> <p>Clone the BCC repository: <pre><code>git clone https://github.com/iovisor/bcc.git\n</code></pre></p> </li> <li> <p>Build BCC: <pre><code>mkdir bcc/build &amp;&amp; cd bcc/build\ncmake ..\nmake\n</code></pre></p> </li> <li> <p>Install BCC: <pre><code>sudo make install\n</code></pre></p> </li> <li> <p>Update the shared library cache: <pre><code>sudo ldconfig\n</code></pre></p> </li> <li> <p>Run kvmexit <pre><code>cd /usr/share/bcc/tools &amp;&amp; sudo ./kvmexit\n</code></pre></p> </li> </ol>"},{"location":"workflow/git/","title":"Git","text":""},{"location":"workflow/git/#git-lfs","title":"Git LFS","text":""},{"location":"workflow/git/#step-1-install-git-lfs","title":"Step 1: Install Git LFS","text":"<p>For Debian/Ubuntu systems, use the following commands:</p> <pre><code>curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\nsudo apt-get install git-lfs\n</code></pre>"},{"location":"workflow/git/#step-2-initialize-git-lfs","title":"Step 2: Initialize Git LFS","text":"<p>After installation, set up Git LFS for your user account by running: <pre><code>git lfs install\n</code></pre></p>"},{"location":"workflow/git/#step-optional-untrack-the-file-from-git","title":"Step optional: Untrack the file from Git:","text":"<p>Use the git rm --cached command to untrack the file1. For example, if your file is named largefile.zip, you would use: <pre><code>git rm --cached largefile.zip\n</code></pre></p>"},{"location":"workflow/git/#step-3-track-the-large-file-with-git-lfs","title":"Step 3: Track the Large File with Git LFS","text":"<p>Before adding and committing the file, you need to tell Git LFS to track it. You can do this with the git lfs track command. For example, if your large file is a .zip file, you would use: <pre><code>git lfs track \"*.zip\"\n</code></pre></p> <p>Replace *.zip with the type of your large file. If you want to track a specific file, you can replace *.zip with the path to your file.</p>"},{"location":"workflow/git/#step-4-add-and-commit-the-file","title":"Step 4: Add and Commit the File","text":"<p>After tracking the file with Git LFS, you can add it to your Git repository and commit it as usual: <pre><code>git add your_large_file.zip\ngit commit -m \"Add large file\"\n</code></pre></p> <p>Replace your_large_file.zip with the path to your large file.</p>"},{"location":"workflow/git/#step-5-push-the-file-to-your-remote-repository","title":"Step 5: Push the File to Your Remote Repository","text":"<p>Finally, you can push your changes to your remote repository: <pre><code>git push origin main\n</code></pre> Replace main with the name of your branch if it\u2019s not main.</p> <p>By following these steps, Git LFS will handle your large files, and you should be able to push them to your remote repository without any issues.</p> <p>Please replace <code>your_large_file.zip</code> and <code>main</code> with your actual file name and branch name respectively.</p>"},{"location":"workflow/git/#git-useful","title":"Git Useful","text":""},{"location":"workflow/git/#untrack-files-to-be-ignored-named-documentationtest-in-git","title":"Untrack files to be ignored named \u201cdocumentation/test\u201d in git:","text":"<p><code>git rm --cached &lt;path&gt;</code> How To Fix Gitignore Not Working</p>"},{"location":"workflow/git/#remove-a-commit-but-keep-the-changes-in-your-working-directory","title":"Remove a commit but keep the changes in your working directory","text":"<p>git reset --soft HEAD~1</p>"},{"location":"workflow/problem_solution/","title":"Problem solution","text":""},{"location":"workflow/problem_solution/#microsoft-edge","title":"Microsoft Edge","text":""},{"location":"workflow/problem_solution/#problem","title":"Problem","text":"<pre><code>sigma_ibo@sigma-ibo:~$ microsoft-edge\n[9283:9283:0402/093408.731168:ERROR:process_singleton_posix.cc(359)] This profile appears to be in use by another Microsoft Edge process (2953) on another computer (localhost.localdomain). Microsoft Edge has locked this profile to prevent corruption. If you're sure no other processes are using this profile, you can unlock it and relaunch Microsoft Edge.\n[9283:9283:0402/093408.731251:ERROR:message_box_dialog.cc(147)] Unable to show a dialog outside the UI thread message loop: Microsoft Edge - This profile appears to be in use by another Microsoft Edge process (2953) on another computer (localhost.localdomain). Microsoft Edge has locked this profile to prevent corruption. If you're sure no other processes are using this profile, you can unlock it and relaunch Microsoft Edge.\n</code></pre>"},{"location":"workflow/problem_solution/#solution","title":"Solution","text":"<p>Delete SingletonLock in <code>/home/sigma_ibo/.config/microsoft-edge</code></p>"},{"location":"workflow/problem_solution/#yocto","title":"Yocto","text":""},{"location":"workflow/problem_solution/#problem-1","title":"Problem 1","text":"<p>File://0001.patch error</p> <p>Unable to find file file://0001-Fix.patch</p>"},{"location":"workflow/problem_solution/#solution-1","title":"Solution 1","text":"<pre><code>cd meta-sigmatek/\ngit branch\ncode ../meta-sigmatek/\ngitk\ngit rebase origin/master\ngit checkout master\ngit reset --hard\ngit checkout master\ngit pull\ngit fetch\ngit branch\ngit branch -D pamhal/virtualization\ngit branch\ngit pull\ngit fetch\ngit branch pamhal/virtual_master\ngit checkout pamhal/virtual_master\ngit branch\ngit status\ngit add recipes-kernel/stek-common/files/x86-64/defconfig\ngit commit\ngit push\ngit push --set-upstream origin pamhal/virtual_master\ngit branch\ngit pull\ncode .\ncd salamander/salamander-core2\n../init.sh -b build -m sigmatek-core2 -d salamander\nbitbake salamander-image -k\n</code></pre>"},{"location":"workflow/problem_solution/#problem-2","title":"Problem 2","text":"<pre><code>ERROR: salamander-image-1.0-r0 do_rootfs: Unable to install packages. Command '/home/sigma_ibo/Develop/Yocto_local/salamander/salamander-core2/build/tmp/work/sigmatek_core2-sigmatek-linux/salamander-image/1.0-r0/recipe-sysroot-native/usr/bin/opkg --volatile-cache -f /home/sigma_ibo/Develop/Yocto_local/salamander/salamander-core2/build/tmp/work/sigmatek_core2-sigmatek-linux/salamander-image/1.0-r0/opkg.conf -t /home/sigma_ibo/Develop/Yocto_local/salamander/salamander-core2/build/tmp/work/sigmatek_core2-sigmatek-linux/salamander-image/1.0-r0/temp/ipktemp/ -o /home/sigma_ibo/Develop/Yocto_local/salamander/salamander-core2/build/tmp/work/sigmatek_core2-sigmatek-linux/salamander-image/1.0-r0/rootfs  --force_postinstall --prefer-arch-to-version --no-install-recommends  --force-maintainer --force-overwrite install cups-locale-en lib32-cups-locale-en' returned 255:\n * opkg_prepare_url_for_install: Couldn't find anything to satisfy 'lib32-cups-locale-en'.\n\nERROR: Logfile of failure stored in: /home/sigma_ibo/Develop/Yocto_local/salamander/salamander-core2/build/tmp/work/sigmatek_core2-sigmatek-linux/salamander-image/1.0-r0/temp/log.do_rootfs.76045\nERROR: Task (/home/sigma_ibo/Develop/Yocto_local/salamander/meta-sigmatek/recipes-sigmatek/images/salamander-image.bb:do_rootfs) failed with exit code '1'\n</code></pre>"},{"location":"workflow/problem_solution/#solution-2","title":"Solution 2","text":"<p>bitbake -c do_cleanall lib32-cups</p>"},{"location":"workflow/problem_solution/#trace-cmd","title":"Trace-cmd","text":"<p>After following Rostedt Tutorial, I had following problems when using:  <pre><code>sudo trace-cmd record -e kvm:kvm_entry -e kvm:kvm_exit -A @3:823 --name Salamander4 -e all\n</code></pre></p>"},{"location":"workflow/problem_solution/#problem-1_1","title":"Problem 1","text":"<p>\"Failed to negotiate timestamps synchronization with the host\" timestamp_error.png</p>"},{"location":"workflow/problem_solution/#problem-2_1","title":"Problem 2","text":"<p>\"Cannot find host / guest tracing into the loaded streams\" kvm_combo_error.png</p>"},{"location":"workflow/problem_solution/#solution_1","title":"Solution","text":"<p>The problem was the trace-cmd version. Set both host and guest to v3.2.0 by copying the files from host to guest: <pre><code>scp /usr/local/bin/trace-cmd root@\"$ip_address\":/usr/bin\nscp /usr/local/lib64/libtracefs.so.1 root@\"$ip_address\":/lib64\nscp /usr/local/lib64/libtraceevent.so.1 root@\"$ip_address\":/lib64\n</code></pre> Now, trace-cmd version 3.2.0 is active and tracing the guest finally works with <code>trace-cmd agent</code> on the guest.</p> <p>Using kernelshark with <code>kernelshark trace.dat -a trace-Salamander4.dat</code> or simply <code>./start_kernelshark.sh</code>, we get the expected visualization. Events of the guest happen between kvm_entry and kvm_exit of the host.</p>"},{"location":"workflow/problem_solution/#bcc","title":"bcc","text":""},{"location":"workflow/problem_solution/#problem-1_2","title":"Problem 1","text":"<p>Unable to find clang libraries <pre><code>sigma_ibo@sigma-ibo:~/Desktop/latency/bcc/build$ cmake ..\n-- Latest recognized Git tag is v0.30.0\n-- Git HEAD is 6a5602cef2ebd97c351554d53a4f95532db6a568\n-- Revision is 0.30.0+6a5602ce (major 0, minor 30, patch 0)\n-- Kernel release: 6.5.0-26-generic\n-- Kernel headers: /usr/src/linux-headers-6.5.0-26-generic\n-- Found LLVM: /usr/lib/llvm-14/include 14.0.0 (Use LLVM_ROOT envronment variable for another version of LLVM)\nCMake Error at CMakeLists.txt:173 (message):\n  Unable to find clang libraries\n\n\n-- Configuring incomplete, errors occurred!\nSee also \"/home/sigma_ibo/Desktop/latency/bcc/CMakeFiles/CMakeOutput.log\".\n</code></pre></p>"},{"location":"workflow/problem_solution/#solution-1_1","title":"Solution 1","text":"<p><pre><code>sudo apt install libclang-dev\n</code></pre> Source</p>"},{"location":"workflow/problem_solution/#problem-2_2","title":"Problem 2","text":"<p>It seems that the library is trying to access the symbol bpf_module_create_b in the shared library libbcc.so.0, but it can\u2019t find it. <pre><code>root@sigma-ibo:/usr/share/bcc/tools# sudo ./kvmexit\nTraceback (most recent call last):\n  File \"/usr/share/bcc/tools/./kvmexit\", line 32, in &lt;module&gt;\n    from bcc import BPF\n  File \"/usr/lib/python3/dist-packages/bcc/__init__.py\", line 27, in &lt;module&gt;\n    from .libbcc import lib, bcc_symbol, bcc_symbol_option, bcc_stacktrace_build_id, _SYM_CB_TYPE\n  File \"/usr/lib/python3/dist-packages/bcc/libbcc.py\", line 20, in &lt;module&gt;\n    lib.bpf_module_create_b.restype = ct.c_void_p\n  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 387, in __getattr__\n    func = self.__getitem__(name)\n  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 392, in __getitem__\n    func = self._FuncPtr((name_or_ordinal, self))\nAttributeError: /lib/x86_64-linux-gnu/libbcc.so.0: undefined symbol: bpf_module_create_b\n</code></pre></p>"},{"location":"workflow/problem_solution/#solution-2_1","title":"Solution 2","text":"<p><pre><code>sudo rm -fr /usr/lib/python3/dist-packages/bcc\ncd /usr/share/bcc/tools &amp;&amp; sudo ./kvmexit\n</code></pre> Source</p>"},{"location":"workflow/problem_solution/#qemu","title":"QEMU","text":""},{"location":"workflow/problem_solution/#problem_1","title":"Problem","text":"<pre><code>$ sudo ./qemu_def.sh \nfailed to parse default acl file `/etc/qemu/bridge.conf'\nqemu-system-x86_64: -netdev bridge,id=e1000,br=nm-bridge: bridge helper failed\n</code></pre>"},{"location":"workflow/problem_solution/#solution_2","title":"Solution","text":"<pre><code>sudo mkdir /etc/qemu &amp;&amp; cd /etc/qemu \necho \"allow nm-bridge\" | sudo tee bridge.conf &gt; /dev/null\n</code></pre>"},{"location":"workflow/problem_solution/#kernel-patch","title":"Kernel Patch","text":""},{"location":"workflow/problem_solution/#problem-1_3","title":"Problem 1","text":"<p>Fully Preemptible Kernel (RT) not showing up in menuconfig </p>"},{"location":"workflow/problem_solution/#solution-1_2","title":"Solution 1","text":"<p>1) Run <code>make mrproper</code> 2) Then run <code>make menuconfig</code> </p> <p>This is the output Source</p> <p>OR </p> <p>In <code>arch/Kconfig</code>, search for the entry: <code>ARCH_SUPPORTS_RT</code>. </p> <p>Change the entry from</p> <p><pre><code>config ARCH_SUPPORTS_RT\n    bool\n</code></pre> to <pre><code>config ARCH_SUPPORTS_RT\n    def_bool y\n</code></pre> When you now also have the <code>EXPERT</code> (General Setup -&gt; Embedded System) flag enabled you should see the option <code>Fully Preemptible Kernel (Real-Time)</code> under General Setup -&gt; Preemption Model.</p> <p>Source</p>"},{"location":"workflow/problem_solution/#problem-2_3","title":"Problem 2","text":"<p>No rule to make target 'debian/canonical-certs.pem'</p>"},{"location":"workflow/problem_solution/#solution-2_2","title":"Solution 2","text":"<p>If you get the certificate error, execute the following in the root of the kernel source <pre><code>scripts/config --disable SYSTEM_TRUSTED_KEYS\nscripts/config --disable SYSTEM_REVOCATION_KEYS\n</code></pre> Then run make again and it should work! Source</p>"},{"location":"workflow/problem_solution/#_1","title":"Problem solution","text":""},{"location":"workflow/useful/","title":"Useful Stuff","text":""},{"location":"workflow/useful/#symbolic-link-to-windows-folder","title":"Symbolic Link to Windows Folder","text":"<p><code>ln -s /media/sigma_ibo/Windows/Dokumente\\ und\\ Einstellungen/Pamibr/Desktop/Masterarbeit/ /home/sigma_ibo/Desktop/</code> Symbolic Link to Windows Folder</p>"},{"location":"workflow/useful/#mount-windows-partition-desktop","title":"Mount Windows partition Desktop","text":"<ul> <li><code>sudo nano /etc/fstab</code> </li> <li>At the end of the file, add: UUID=0E58A36658A34B73 /home/sigma_ibo/Desktop ntfs defaults 0 0, it looks like  this </li> <li>reboot</li> </ul>"},{"location":"workflow/useful/#how-to-extract-unzip-tarxz-file","title":"How to Extract (Unzip) tar.xz File","text":"<p>How to Extract (Unzip) tar.xz File</p>"},{"location":"workflow/useful/#launch-programs-after-startup","title":"Launch programs after startup","text":"<ul> <li><code>nano /home/sigma_ibo/startup.sh</code></li> <li><code>chmod +x /home/sigma_ibo/startup.sh</code></li> <li>File: startup.sh </li> <li>Configure Startup Apps</li> </ul>"},{"location":"workflow/useful/#install-gnome","title":"Install gnome","text":"<p><code>sudo apt install gnome-shell-extension-ubuntu-dock</code></p>"},{"location":"workflow/useful/#desktop-folders-not-visible","title":"Desktop folders not visible","text":"<p><code>sudo apt install ubuntu-desktop</code></p>"},{"location":"workflow/useful/#windows-11-on-qemu-and-display-settings","title":"Windows 11 on QEMU and display settings","text":"<p>Install Windows 11 in KVM on Ubuntu 22.04 Execute virtio-win-guest-tools in VM Windows 10 VM shows 100% CPU QEMU settings: QEMU, XML win11 Windows 10 VM Settings</p>"},{"location":"workflow/useful/#remove-keyring-from-edge","title":"Remove keyring from Edge","text":"<p>To stop being prompted to unlock the \u2018default\u2019 keyring on boot, set a blank password for the keyring. - Open the utility \u201cPasswords &amp; Keys\u201d. If not installed: <code>sudo apt-get install seahorse</code> - Right-click the \u201cLogin\u201d folder and select \u201cChange Password\u201d. - Enter your old password and leave the new password blank.</p>"},{"location":"workflow/useful/#see-how-many-cores-you-have","title":"See how many cores you have","text":"<p><code>nproc</code> or <code>cat /proc/cpuinfo | grep processor | wc -l</code> or <code>cat /proc/cpuinfo | grep 'core id'</code> or <code>lscpu</code></p>"},{"location":"workflow/useful/#start_qemush-from-everywhere","title":"start_qemu.sh from everywhere","text":"<p>Script start_qemu.sh needs to be in <code>/home/sigma_ibo/Desktop/Masterarbeit/masterthesis-documentation/QEMU/</code>.  <pre><code>sudo nano ~/.bashrc\nexport PATH=$PATH:/home/sigma_ibo/Desktop/Masterarbeit/documentation/resources/QEMU/\n</code></pre></p>"},{"location":"workflow/useful/#add-konsole-to-replace-console","title":"Add konsole to replace console","text":"<p>nautilus-open-any-terminal Change default terminal with right-click option \"Open in Terminal\" in file manager</p>"},{"location":"workflow/useful/#ssh-ohne-passwort","title":"SSH ohne Passwort","text":"<p>Um eine SSH-Verbindung von Ihrem Host-Computer zu Ihrem Gast-Computer (oder Server) herzustellen, k\u00f6nnen Sie die folgenden Schritte ausf\u00fchren:</p> <ol> <li>Generieren Sie ein SSH-Schl\u00fcsselpaar auf Ihrem Host-Computer. Sie k\u00f6nnen dies mit dem Befehl <code>ssh-keygen</code> tun. Sie werden aufgefordert, ein Passwort einzugeben, aber Sie k\u00f6nnen einfach Enter dr\u00fccken, um kein Passwort zu setzen (obwohl dies aus Sicherheitsgr\u00fcnden nicht empfohlen wird).</li> </ol> <pre><code>ssh-keygen\n</code></pre> <ol> <li>Kopieren Sie Ihren \u00f6ffentlichen Schl\u00fcssel auf den Gast-Computer. Sie k\u00f6nnen dies mit dem Befehl <code>ssh-copy-id</code> tun. Ersetzen Sie <code>benutzername</code> durch Ihren Benutzernamen auf dem Gast-Computer und <code>ip_address</code> durch die IP-Adresse des Gast-Computers.</li> </ol> <pre><code>ssh-copy-id root@192.168.1.51\n</code></pre> <ol> <li>Stellen Sie eine SSH-Verbindung zum Gast-Computer her. Sie k\u00f6nnen dies mit dem Befehl <code>ssh</code> tun. Ersetzen Sie wieder <code>benutzername</code> und <code>ip_address</code> durch Ihren Benutzernamen und die IP-Adresse des Gast-Computers.</li> </ol> <pre><code>ssh root@192.168.1.51\n</code></pre> <p>Nachdem Sie diese Schritte ausgef\u00fchrt haben, sollten Sie in der Lage sein, sich ohne Passwort bei Ihrem Gast-Computer anzumelden. </p> <p>Wenn Sie den ssh-copy-id Befehl verwenden, wird Ihr \u00f6ffentlicher SSH-Schl\u00fcssel in der Datei <code>~/.ssh/authorized_keys</code> auf dem Gast-Computer (dem Computer, zu dem Sie eine SSH-Verbindung herstellen) gespeichert.</p> <p>Jede Zeile in dieser Datei repr\u00e4sentiert einen \u00f6ffentlichen Schl\u00fcssel, der f\u00fcr die Authentifizierung zugelassen ist. Wenn Sie also mehrere Schl\u00fcssel haben, die Sie verwenden, um sich bei diesem Computer anzumelden, wird jeder Schl\u00fcssel als separate Zeile in dieser Datei angezeigt</p>"},{"location":"workflow/useful/#check-on-which-cpu-a-task-is-running","title":"Check on which CPU a task is running","text":"<p><code>ps -eo pid,psr,comm | grep &lt;name&gt;</code></p>"},{"location":"workflow/useful/#limit-wsl2-resources","title":"Limit WSL2 resources","text":"<p>Edit the WSL config to limit the memory usage as mentioned here. <pre><code>#turn off all wsl instances such as docker-desktop\nwsl --shutdown\nnotepad \"$env:USERPROFILE/.wslconfig\"\n</code></pre> Set the values you want for CPU core and Memory:</p> <pre><code>[wsl2]\nmemory=3GB   # Limits VM memory in WSL 2 up to 3GB\nprocessors=2 # Makes the WSL 2 VM use two virtual processors\n</code></pre>"},{"location":"workflow/useful/#connect-to-hardware-salamander-4","title":"Connect to hardware Salamander 4","text":"<p>ssh root@192.168.1.244</p>"},{"location":"workflow/useful/#boot-parameters","title":"Boot parameters","text":"<p>cat /proc/cmdline</p>"},{"location":"workflow/useful/#stress-the-cpus","title":"Stress the CPUs","text":"<p>stress -c $(nproc)</p>"},{"location":"workflow/useful/#check-cpu-maxmhz-minmhz-current-mhz","title":"Check cpu MAXMHZ, MINMHZ, CURRENT MHZ","text":"<pre><code>$ lscpu --all --extended\nCPU NODE SOCKET CORE L1d:L1i:L2:L3 ONLINE    MAXMHZ   MINMHZ      MHZ\n  0    0      0    0 0:0:0:0          yes 5000,0000 400,0000 2900.000\n  1    0      0    1 4:4:1:0          yes 5000,0000 400,0000 2900.000\n  2    0      0    2 8:8:2:0          yes 5200,0000 400,0000 2900.000\n  3    0      0    3 12:12:3:0        yes 5200,0000 400,0000 4174.117\n  4    0      0    4 16:16:4:0        yes 5000,0000 400,0000 2900.000\n  5    0      0    5 20:20:5:0        yes 5000,0000 400,0000 2900.000\n  6    0      0    6 24:24:6:0        yes 4000,0000 400,0000 2926.742\n  7    0      0    7 25:25:6:0        yes 4000,0000 400,0000 2900.000\n  8    0      0    8 26:26:6:0        yes 4000,0000 400,0000 2900.000\n  9    0      0    9 27:27:6:0        yes 4000,0000 400,0000 2900.000\n 10    0      0   10 28:28:7:0        yes 4000,0000 400,0000 3332.776\n 11    0      0   11 29:29:7:0        yes 4000,0000 400,0000 2900.000\n 12    0      0   12 30:30:7:0        yes 4000,0000 400,0000 2900.000\n 13    0      0   13 31:31:7:0        yes 4000,0000 400,0000 3218.336\n</code></pre>"},{"location":"workflow/useful/#see-threads-of-a-task","title":"See threads of a task","text":"<pre><code>sigma_ibo@sigma-ibo:~$ ls /proc/464458/task | wc -l\n6\nsigma_ibo@sigma-ibo:~$ htop -H -p 464458\n</code></pre>"},{"location":"workflow/useful/#thread-priorities","title":"Thread priorities","text":"<p>Set / Manipulate Real Time Attributes of a Linux Process Full list of all threads on the system with process id, thread id, short name, scheduling policy, nice value and realtime-priority. ps reports SCHED_DEADLINE as DLN, SCHED_OTHER as TS, SCHED_BATCH as B, SCHED_IDLE as IDL, SCHED_FIFO as FF and SCHED_RR as RR. <pre><code>ps axHo psr,pid,lwp,args,policy,nice,rtprio\n</code></pre> All the tasks on CPU 13 <pre><code>ps axHo psr,pid,lwp,args,policy,nice,rtprio | awk '$1 == 13'\n</code></pre> All rt processes <pre><code>ps axHo psr,pid,lwp,args,policy,nice,rtprio | grep -P '\\s[0-9]+\\s*$'\nps axHo psr,pid,lwp,args,policy,nice,rtprio | awk '$NF ~ /^[0-9]+$/' | sort -k4,4 -V &gt; rt_processes.txt\n</code></pre> Set all threads of a process to a real-time priority <pre><code>ps -T -p $(pgrep -f \"qemu-system-x86_64 -M pc,ac\") | awk '{print $2}' | tail -n +2 | xargs -I {} sudo chrt -f -p 10 {}\n</code></pre> Watch it <pre><code>watch -d -c -n 1 \"ps axHo psr,pid,lwp,args,policy,nice,rtprio | awk '\\$1 == 4'\"\n</code></pre></p>"},{"location":"workflow/useful/#test-suite-rt-tests","title":"Test suite: rt-tests","text":"<p>An Analysis of the Real-Time Performance of Linux Kernels The rt-tests test suite contains programs to test various real-time Linux features; more details are available here. The step-by-step procedure to install the rt-tests suite from the source is given below.</p> <p>First, you need to install the libraries: <pre><code>sudo apt-get install build-essential libnuma-dev\n</code></pre></p> <p>Next, clone the code and build from the source: <pre><code>git clone git://git.kernel.org/pub/scm/utils/rt-tests/rt-tests.git\ncd rt-tests\ngit checkout stable/v1.0\nmake all\nmake install\n</code></pre></p>"},{"location":"workflow/useful/#useful-not-needed","title":"Useful Not needed","text":""},{"location":"workflow/useful/#add-more-cpus-to-qemu-virtual-machine-with-smp-option","title":"Add more CPUs to QEMU virtual machine with -smp option","text":"<p>The -smp option specifies the number of CPUs</p> <p>Replace n with the number of CPUs you want to add. For example, if you want to add 4 CPUs, you would use -smp cpus=4.</p> <p>After making these changes, the specified number of CPUs will be available when you boot your Yocto image with this script.  <pre><code>exec qemu-system-x86_64 -M pc,accel=kvm -kernel ./bzImage \\\n-m 2048 -drive file=salamander-image-sigmatek-core2.ext4,format=raw,media=disk \\\n-append \"console=ttyS0 console=tty1 root=/dev/sda rw panic=1 sigmatek_lrt.QEMU=1 ip=dhcp rootfstype=ext4 \\\n-net nic,model=e1000,netdev=e1000 -netdev bridge,id=e1000,br=nm-bridge \\\n-fsdev local,security_model=none,id=fsdev0,path=drive-c -device virtio-9p-pci,id=fs0,fsdev=fsdev0,mount_&gt;\n-drive if=pflash,format=qcow2,file=ovmf.code.qcow2 \\\n-smp cpus=n \\\n-no-reboot -nographic\n</code></pre> Check with: <code>cat /sys/devices/system/cpu/online</code> <pre><code>root@sigmatek-core2:~# cat /sys/devices/system/cpu/online\n0-9\n</code></pre></p>"},{"location":"workflow/useful/#isolate-cpus-in-qemu-with-isolcpus","title":"Isolate CPUs in QEMU with isolcpus","text":"<p>To use isolcpus in a Yocto image, you need to add it to the kernel command line parameters. In your case, these parameters are specified in the -append option in your QEMU command. Add isolcpus=x,y,z. Replace x,y,z with the CPU cores you want to isolate. For example, if you want to isolate cores 0, 1 and 2, you would use isolcpus=0,1,2. <pre><code>exec qemu-system-x86_64 -M pc,accel=kvm -kernel ./bzImage \\\n-m 2048 -drive file=salamander-image-sigmatek-core2.ext4,format=raw,media=disk \\\n-append \"console=ttyS0 console=tty1 root=/dev/sda rw panic=1 sigmatek_lrt.QEMU=1 ip=dhcp rootfstype=ext4 isolcpus=0,1,2\" \\\n-net nic,model=e1000,netdev=e1000 -netdev bridge,id=e1000,br=nm-bridge \\\n-fsdev local,security_model=none,id=fsdev0,path=drive-c -device virtio-9p-pci,id=fs0,fsdev=fsdev0,mount_&gt;\n-drive if=pflash,format=qcow2,file=ovmf.code.qcow2 \\\n-smp cpus=n \\\n-no-reboot -nographic\n</code></pre> Check with: <code>cat /sys/devices/system/cpu/isolated</code> <pre><code>root@sigmatek-core2:~# cat /sys/devices/system/cpu/isolated\n0-2\n</code></pre></p>"},{"location":"workflow/useful/#gid-pid-of-processes","title":"Gid PID Of processes","text":"<p>Start latency and write output to latency_output.txt: <code>latency -T 60 &gt; latency_output.txt 2&gt;&amp;1 &amp;</code> Get ID of xenomai task: <code>ps aux | grep latency</code> <pre><code>root@sigmatek-core2:~# latency -T 60 &gt; latency_output.txt 2&gt;&amp;1 &amp;\n[1] 557\nroot@sigmatek-core2:~# ps aux | grep latency\nroot       557  0.0  0.6  14040 12852 ttyS0    SLl  11:34   0:00 latency -T 60\nroot       563  0.0  0.0   3256  1148 ttyS0    S+   11:34   0:00 grep latency\n</code></pre></p>"},{"location":"workflow/useful/#assign-tasks-to-the-isolated-cpus","title":"Assign tasks to the isolated CPUs","text":"<p>To assign these latency tasks to the isolated CPUs, you can use the taskset command with the process ID (PID) of each latency task. For example, if you want to assign the latency task with PID 536 to CPU 1, you would use:</p> <p><code>taskset -pc x abc</code></p> <p>Remember to replace abc with the actual PID of the latency task. You can repeat this process for each latency task and each isolated CPU.</p>"},{"location":"workflow/useful/#kill-processes","title":"Kill processes","text":"<p>Kill processes with <code>kill x</code></p>"},{"location":"workflow/useful/#m-error-message","title":"^M error message","text":"<p>The error message you're seeing is typically caused by a mismatch in line endings. Scripts that have been edited or created on Windows use a different line ending (<code>\\r\\n</code>) than Unix/Linux (<code>\\n</code>). The <code>^M</code> in the error message is a visual representation of <code>\\r</code> (carriage return), which is not expected or understood by the Linux shell.</p> <p>You can convert the line endings of your script to the Unix format using a tool like <code>dos2unix</code>. Here's how you can do it:</p> <pre><code>sudo apt-get install dos2unix  # Install dos2unix tool\ndos2unix &lt;file&gt;\n</code></pre>"},{"location":"workflow/useful/#split-too-long-prompt","title":"Split too long Prompt","text":"<p>ChatGPT PROMPTs Splitter</p>"},{"location":"workflow/useful/#configure-ip-addresses","title":"Configure ip addresses","text":"<p>Configure PC to <code>10.10.1.1</code>.  Salamander Gateway set to <code>10.10.1.229</code></p>"},{"location":"workflow/useful/#ubuntu-vm-on-virtual-machine-manager","title":"Ubuntu VM on virtual machine manager","text":"<p>After giving the VM access to the vsocket, and installing trace-cmd along with dependancies, run <code>trace-cmd agent</code>. Now, the guest is able to negotiate with host about timestamp synchronization. After running <code>./start_kernelshark.sh</code>, we can view KVM Combo plots</p>"},{"location":"workflow/vscode/","title":"VSCode","text":"command Description ^.word.$ Delete lines containing word ^(\\s)*$\\n Delete blank lines"},{"location":"workflow/meetings/rauh/","title":"Rauh Fragen","text":"<ul> <li>Code / Gro\u00df oder klein?</li> <li>This script will be adjusted </li> </ul>"},{"location":"workflow/meetings/richard/","title":"Richard","text":""},{"location":"workflow/meetings/richard/#am-dienstag-20-februar-2024-1120","title":"Am Dienstag, 20. Februar 2024, 11:20","text":"<p>Hallo Halil,</p> <p>375us ist halt weit weg von dem was Salamander sonst an Latenz hat. Damit kann man nur wenig anfangen. Aber ich w\u00fcrde erstmal schauen die Latenz besser in Griff zu bekommen. \u2705</p> <p>Wie k\u00f6nnte ich das am besten besser in Griff bekommen? Hast du da einen Weg f\u00fcr mich? Oder generell wie ich vorgehen soll?</p> <p>Wie letztens erw\u00e4hnt, im ersten Schritt daf\u00fcr sorgen, dass die VM immer die CPU hat und m\u00f6glichst wenig unterbrochen wird. \u2705</p> <p>Ich wei\u00df jetzt nicht genau was deine Aufgabe ist.</p> <p>So lautet der Titel meiner Masterarbeit: Virtualisierung eines Echtzeit-Betriebssystems zur Steuerung eines Roboters mit Schwerpunkt auf die Einhaltung der Echtzeit</p> <p>Das klingt eh gut. Du kannst am Host auch mal messen wann die VM immer die CPU hat und mit dem Gast vergleichen. Da solltest dann eine sch\u00f6ne Korrelation zu den Ausrei\u00dfern sehen. Mit den VMEnter/Exit Tracpoints solltest das gut sehen. Siehe: https://www.youtube.com/watch?v=v0ocveEsvNU \u274c</p> <p>So kannst Schritt f\u00fcr Schritt die Latenz verbessern und jeweils nachweisen was nun wie viel gebracht hat. \u274c</p> <p>LG, //richard</p>"},{"location":"workflow/meetings/richard/#am-dienstag-20-februar-2024-1241","title":"Am Dienstag, 20. Februar 2024, 12:41","text":"<p>Hallo Halil,</p> <p>Ich habe bis jetzt folgendes getan, um die Latenz zu reduzieren</p> <p>1) Die Option -smp cpus=10 im QEMU-Befehl hinzugef\u00fcgt um die Anzahl der CPUs zu erh\u00f6hen auf 10</p> <p>Was war die Idee dahinter? Mehr CPUs im Gast bringt nur was wenn gleich viele am Host hast. Und die Latenz an sich wird immer pro CPU gemessen. D.h. der Test pinnt einen Thread auf eine CPU. \u2705</p> <p>2) isolcpus=0,1,2 zur -append Option in QEMU hinzugef\u00fcgt, um 3 CPUs zu isolieren</p> <p>Naja, du musst das am Host machen. Der Gast ist ja schon echtzeitf\u00e4hig, jetzt gilt es daf\u00fcr zu sorgen, dass der Host ihm nicht in die Suppe spuckt. \u2705</p> <p>3) Jetzt benutze ich taskset um diese cpus zu xenomai zuzuweisen und dann werde ich nochmal testen</p> <p>Bin ich am richtigen Weg?</p> <p>Nicht wirklich. Du wirst am Host viel drehen m\u00fcssen. \u2705</p> <p>LG, //richard</p>"},{"location":"workflow/meetings/richard/#richard-meeting-11032024","title":"Richard Meeting 11.03.2024","text":"<p>CPU isolierung l\u00e4uft auf User space, nicht kernel space QEMU mit echtzeit prio chrt einschalten aber niedrige prio 1-99</p> <p>1) out-of-of-the-box 2) cpi isolated auf user space 3) realtime priority experimentieren 4) cpu soll keine interrupts behandeln -&gt; welche cpu soll ich w\u00e4hlen? 5) HYprerthreading ausschalten damit cpu cores nicht geteilt werden 6) kernelshark</p> <p>https://www.suse.com/c/cpu-isolation-nohz_full-part-3/ https://sigma-star.at/blog/2022/02/linux-proc-prios/ https://www.osadl.org/Create-a-latency-plot-from-cyclictest-hi.bash-script-for-latency-plot.0.html</p>"},{"location":"workflow/meetings/richard/#richard-meeting-19032024","title":"Richard Meeting 19.03.2024","text":"<p>[  235.780378][  T336] X-LRT-Timer: Sigmatek LRT Driver: time-keeper: detected overrun when waiting on period, ovr=2, res=-110</p> <p>QEMU, VirtualBox, KVM, and Hyper-V? \u2192 Salamander4</p> <p>kernel patch kernel-tasks chrt kvm_exit warum? kernel tasks auf andere cpu pinnen oder h\u00f6here prio als andere kernel tasks haben -&gt; zb netzwerkkarte</p>"},{"location":"workflow/meetings/richard/#richard-meeting-09042024","title":"Richard Meeting 09.04.2024","text":""},{"location":"workflow/meetings/richard/#isolate-cpu","title":"isolate CPU","text":"<p>taskset</p>"},{"location":"workflow/meetings/richard/#defconfig","title":"defconfig","text":"<p>CONFIG_PARAVIRT=y CONFIG_KVM_GUEST=y CONFIG_X86_IOAT_VAPIC_BROKEN_CTL=y CONFIG_MTRR_SANITIZER=y CONFIG_ARCH_CPUIDLE_HALTPOLL=y CONFIG_HUGETLBFS=y</p>"},{"location":"workflow/meetings/richard/#smp_affinity","title":"smp_affinity","text":"<p>cat /proc/irq//smp_affinity sudo chmod 777 /proc/irq//smp_affinity sudo echo dffff &gt; /proc/irq/*/smp_affinity  </p>"},{"location":"workflow/meetings/richard/#enable-apicv","title":"Enable APICV","text":"<p>/sys/module/kvm_intel/parameters/enable_apicv</p>"},{"location":"workflow/meetings/richard/#qemu_vapic","title":"QEMU_vapic","text":"<p>-cpu host,hv-passthrough</p>"},{"location":"workflow/meetings/richard/#trace-cmd-report-host-and-guest","title":"trace-cmd report host and guest","text":"<p>results_guest_report.txt results_host_report.txt</p> <p>https://www.sigma-star.at/blog/2022/02/linux-proc-prios/</p>"},{"location":"workflow/meetings/richard/#richard-meeting-15052024","title":"Richard Meeting 15.05.2024","text":"<p>Richard Weinberger 13:12 lstopo aus paket hwloc Richard Weinberger 13:34 https://docs.kernel.org/trace/ftrace.html#latency-tracing-and-events Richard Weinberger 13:37 https://access.redhat.com/documentation/de-de/red_hat_enterprise_linux_for_real_time/7/html/tuning_guide/latency_tracing_using_trace-cmd Richard Weinberger 13:38 \"trace-cmd latency tracer\" Richard Weinberger 13:49 CONFIG_RCU_CPU_STALL_TIMEOUT Richard Weinberger 13:52 https://wiki.linuxfoundation.org/realtime/documentation/technical_details/rcu</p>"},{"location":"workflow/meetings/richard/#richard-meeting-28052024","title":"Richard Meeting 28.05.2024","text":"<ul> <li>QEMU different threads</li> <li>cat /proc/interrupts</li> <li>Kernel parameters<ul> <li>CONFIG_RCU_CPU_STALL_TIMEOUT</li> <li>CONFIG_PREEMPT_RCU=y</li> <li>CONFIG_LOCKUP_DETECTOR</li> <li>CONFIG_DETECT_HUNG_TASK</li> <li>CONFIG_NO_HZ</li> <li>CONFIG_HZ_*</li> <li>CONFIG_NO_HZ_FULL</li> </ul> </li> <li>2 CPUs? smp</li> </ul> <p>RT_Performance_Tuning_Best_Practice_KVM_VM.pdf results in xenomai_compare.md QEMU with 2 CPUs</p> <p>\u274c\u2705</p>"},{"location":"workflow/meetings/wober/","title":"Wober","text":""},{"location":"workflow/meetings/wober/#thema","title":"Thema","text":"<ul> <li> <p>Erstellung einer Echtzeit-Robotersteuerungsplattform:  Ich plane, eine Plattform zu erstellen, die auf Salamander OS basiert und Xenomai f\u00fcr Echtzeitfunktionen nutzt. Diese Plattform wird die Grundlage f\u00fcr meine Robotersteuerungsanwendungen sein.</p> </li> <li> <p>Evaluation der Virtualisierungsplattform:  Ich werde verschiedene Virtualisierungsplattformen wie QEMU, Hyper-V, Virtual Box usw. evaluieren. Dies ist ein wichtiger Schritt, um die beste Plattform f\u00fcr meine Anforderungen zu finden.</p> </li> <li> <p>Anbindung eines Roboters \u00fcber eine VARAN-Bus Schnittstelle: Ich plane, einen Roboter in mein System zu integrieren. Ich werde eine VARAN-Bus Schnittstelle verwenden, um eine schnelle und zuverl\u00e4ssige Kommunikation zwischen dem Roboter und dem Steuerungssystem zu gew\u00e4hrleisten.</p> </li> <li> <p>Erstellung und Konfiguration des Systems in der Yocto-Umgebung:  Ich werde das Yocto-Framework verwenden, um mein Embedded Linux System zu erstellen und zu konfigurieren. Yocto bietet viele Tools und Funktionen, die mir bei der Erstellung und Konfiguration meines Systems helfen k\u00f6nnen.</p> </li> <li> <p>Verbesserung der Reaktionszeit und Zuverl\u00e4ssigkeit von Roboteranwendungen:  Mein Hauptziel ist es, herauszufinden, wie die Integration von Echtzeitfunktionen und effizienten Kommunikationssystemen die Reaktionszeit und Zuverl\u00e4ssigkeit von Roboteranwendungen verbessern kann. Ich strebe an, die Leistung und Zuverl\u00e4ssigkeit meiner Roboteranwendungen zu verbessern, indem ich ihre F\u00e4higkeit verbessere, in Echtzeit auf Ereignisse zu reagieren.</p> </li> </ul>"},{"location":"workflow/meetings/wober/#vorteile","title":"Vorteile","text":"<ul> <li> <p>Fehlerbehebung und Optimierung: Durch die Virtualisierung k\u00f6nnen Entwickler Probleme in Echtzeitsystemen identifizieren und beheben, ohne die tats\u00e4chlichen Systeme zu beeintr\u00e4chtigen. Sie k\u00f6nnen verschiedene Szenarien simulieren und die Leistung des Systems unter diesen Bedingungen analysieren.</p> </li> <li> <p>Sicherheit und Zuverl\u00e4ssigkeit: Die Virtualisierung erm\u00f6glicht es, das Verhalten von Echtzeitsystemen in Ausnahmesituationen zu testen, ohne tats\u00e4chliche Risiken einzugehen. Dies kann dazu beitragen, die Sicherheit und Zuverl\u00e4ssigkeit dieser Systeme zu verbessern.</p> </li> <li> <p>Kostenersparnis: Die Verwendung von virtuellen Modellen anstelle von physischen Prototypen kann zu erheblichen Kosteneinsparungen f\u00fchren, insbesondere in den fr\u00fchen Phasen der Entwicklung.</p> </li> <li> <p>Flexibilit\u00e4t: Mit der Virtualisierung k\u00f6nnen verschiedene Konfigurationen und Anpassungen von Echtzeitsystemen getestet werden, ohne dass \u00c4nderungen an der Hardware vorgenommen werden m\u00fcssen.</p> </li> </ul>"},{"location":"workflow/meetings/wober/#zu-beachten","title":"Zu beachten","text":"<p>Kapitel 1: Ich muss begr\u00fcnden warum ich das mache weil es gibt schon bestehende materialien, warum neu? Nicht wegen Firma! Welche Requirements? basieren auf normen? physik? begr\u00fcnden.  Problem: Integration von Echtzeit-Funktionen (Harter Echtzeit) in eine virtualisierte Robotersteuerungsplattform</p>"}]}